{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "#import keras.callback as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     slen  swid  plen  pwid           class\n",
      "0     5.1   3.5   1.4   0.2     Iris-setosa\n",
      "1     4.9   3.0   1.4   0.2     Iris-setosa\n",
      "2     4.7   3.2   1.3   0.2     Iris-setosa\n",
      "3     4.6   3.1   1.5   0.2     Iris-setosa\n",
      "4     5.0   3.6   1.4   0.2     Iris-setosa\n",
      "5     5.4   3.9   1.7   0.4     Iris-setosa\n",
      "6     4.6   3.4   1.4   0.3     Iris-setosa\n",
      "7     5.0   3.4   1.5   0.2     Iris-setosa\n",
      "8     4.4   2.9   1.4   0.2     Iris-setosa\n",
      "9     4.9   3.1   1.5   0.1     Iris-setosa\n",
      "10    5.4   3.7   1.5   0.2     Iris-setosa\n",
      "11    4.8   3.4   1.6   0.2     Iris-setosa\n",
      "12    4.8   3.0   1.4   0.1     Iris-setosa\n",
      "13    4.3   3.0   1.1   0.1     Iris-setosa\n",
      "14    5.8   4.0   1.2   0.2     Iris-setosa\n",
      "15    5.7   4.4   1.5   0.4     Iris-setosa\n",
      "16    5.4   3.9   1.3   0.4     Iris-setosa\n",
      "17    5.1   3.5   1.4   0.3     Iris-setosa\n",
      "18    5.7   3.8   1.7   0.3     Iris-setosa\n",
      "19    5.1   3.8   1.5   0.3     Iris-setosa\n",
      "20    5.4   3.4   1.7   0.2     Iris-setosa\n",
      "21    5.1   3.7   1.5   0.4     Iris-setosa\n",
      "22    4.6   3.6   1.0   0.2     Iris-setosa\n",
      "23    5.1   3.3   1.7   0.5     Iris-setosa\n",
      "24    4.8   3.4   1.9   0.2     Iris-setosa\n",
      "25    5.0   3.0   1.6   0.2     Iris-setosa\n",
      "26    5.0   3.4   1.6   0.4     Iris-setosa\n",
      "27    5.2   3.5   1.5   0.2     Iris-setosa\n",
      "28    5.2   3.4   1.4   0.2     Iris-setosa\n",
      "29    4.7   3.2   1.6   0.2     Iris-setosa\n",
      "..    ...   ...   ...   ...             ...\n",
      "120   6.9   3.2   5.7   2.3  Iris-virginica\n",
      "121   5.6   2.8   4.9   2.0  Iris-virginica\n",
      "122   7.7   2.8   6.7   2.0  Iris-virginica\n",
      "123   6.3   2.7   4.9   1.8  Iris-virginica\n",
      "124   6.7   3.3   5.7   2.1  Iris-virginica\n",
      "125   7.2   3.2   6.0   1.8  Iris-virginica\n",
      "126   6.2   2.8   4.8   1.8  Iris-virginica\n",
      "127   6.1   3.0   4.9   1.8  Iris-virginica\n",
      "128   6.4   2.8   5.6   2.1  Iris-virginica\n",
      "129   7.2   3.0   5.8   1.6  Iris-virginica\n",
      "130   7.4   2.8   6.1   1.9  Iris-virginica\n",
      "131   7.9   3.8   6.4   2.0  Iris-virginica\n",
      "132   6.4   2.8   5.6   2.2  Iris-virginica\n",
      "133   6.3   2.8   5.1   1.5  Iris-virginica\n",
      "134   6.1   2.6   5.6   1.4  Iris-virginica\n",
      "135   7.7   3.0   6.1   2.3  Iris-virginica\n",
      "136   6.3   3.4   5.6   2.4  Iris-virginica\n",
      "137   6.4   3.1   5.5   1.8  Iris-virginica\n",
      "138   6.0   3.0   4.8   1.8  Iris-virginica\n",
      "139   6.9   3.1   5.4   2.1  Iris-virginica\n",
      "140   6.7   3.1   5.6   2.4  Iris-virginica\n",
      "141   6.9   3.1   5.1   2.3  Iris-virginica\n",
      "142   5.8   2.7   5.1   1.9  Iris-virginica\n",
      "143   6.8   3.2   5.9   2.3  Iris-virginica\n",
      "144   6.7   3.3   5.7   2.5  Iris-virginica\n",
      "145   6.7   3.0   5.2   2.3  Iris-virginica\n",
      "146   6.3   2.5   5.0   1.9  Iris-virginica\n",
      "147   6.5   3.0   5.2   2.0  Iris-virginica\n",
      "148   6.2   3.4   5.4   2.3  Iris-virginica\n",
      "149   5.9   3.0   5.1   1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRiCkkb8qIQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2c1406beb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#IMPORTING DATA\n",
    "filename = \"iris.csv\"\n",
    "names = [\"slen\",\"swid\",\"plen\",\"pwid\",\"class\"]\n",
    "data = pandas.read_csv(filename,names=names,sep=\",\")\n",
    "print(data)\n",
    "\n",
    "data.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     slen  swid  plen  pwid           class\n",
      "0     5.1   3.5   1.4   0.2     Iris-setosa\n",
      "1     4.9   3.0   1.4   0.2     Iris-setosa\n",
      "2     4.7   3.2   1.3   0.2     Iris-setosa\n",
      "3     4.6   3.1   1.5   0.2     Iris-setosa\n",
      "4     5.0   3.6   1.4   0.2     Iris-setosa\n",
      "5     5.4   3.9   1.7   0.4     Iris-setosa\n",
      "6     4.6   3.4   1.4   0.3     Iris-setosa\n",
      "7     5.0   3.4   1.5   0.2     Iris-setosa\n",
      "8     4.4   2.9   1.4   0.2     Iris-setosa\n",
      "9     4.9   3.1   1.5   0.1     Iris-setosa\n",
      "10    5.4   3.7   1.5   0.2     Iris-setosa\n",
      "11    4.8   3.4   1.6   0.2     Iris-setosa\n",
      "12    4.8   3.0   1.4   0.1     Iris-setosa\n",
      "13    4.3   3.0   1.1   0.1     Iris-setosa\n",
      "14    5.8   4.0   1.2   0.2     Iris-setosa\n",
      "15    5.7   4.4   1.5   0.4     Iris-setosa\n",
      "16    5.4   3.9   1.3   0.4     Iris-setosa\n",
      "17    5.1   3.5   1.4   0.3     Iris-setosa\n",
      "18    5.7   3.8   1.7   0.3     Iris-setosa\n",
      "19    5.1   3.8   1.5   0.3     Iris-setosa\n",
      "20    5.4   3.4   1.7   0.2     Iris-setosa\n",
      "21    5.1   3.7   1.5   0.4     Iris-setosa\n",
      "22    4.6   3.6   1.0   0.2     Iris-setosa\n",
      "23    5.1   3.3   1.7   0.5     Iris-setosa\n",
      "24    4.8   3.4   1.9   0.2     Iris-setosa\n",
      "25    5.0   3.0   1.6   0.2     Iris-setosa\n",
      "26    5.0   3.4   1.6   0.4     Iris-setosa\n",
      "27    5.2   3.5   1.5   0.2     Iris-setosa\n",
      "28    5.2   3.4   1.4   0.2     Iris-setosa\n",
      "29    4.7   3.2   1.6   0.2     Iris-setosa\n",
      "..    ...   ...   ...   ...             ...\n",
      "120   6.9   3.2   5.7   2.3  Iris-virginica\n",
      "121   5.6   2.8   4.9   2.0  Iris-virginica\n",
      "122   7.7   2.8   6.7   2.0  Iris-virginica\n",
      "123   6.3   2.7   4.9   1.8  Iris-virginica\n",
      "124   6.7   3.3   5.7   2.1  Iris-virginica\n",
      "125   7.2   3.2   6.0   1.8  Iris-virginica\n",
      "126   6.2   2.8   4.8   1.8  Iris-virginica\n",
      "127   6.1   3.0   4.9   1.8  Iris-virginica\n",
      "128   6.4   2.8   5.6   2.1  Iris-virginica\n",
      "129   7.2   3.0   5.8   1.6  Iris-virginica\n",
      "130   7.4   2.8   6.1   1.9  Iris-virginica\n",
      "131   7.9   3.8   6.4   2.0  Iris-virginica\n",
      "132   6.4   2.8   5.6   2.2  Iris-virginica\n",
      "133   6.3   2.8   5.1   1.5  Iris-virginica\n",
      "134   6.1   2.6   5.6   1.4  Iris-virginica\n",
      "135   7.7   3.0   6.1   2.3  Iris-virginica\n",
      "136   6.3   3.4   5.6   2.4  Iris-virginica\n",
      "137   6.4   3.1   5.5   1.8  Iris-virginica\n",
      "138   6.0   3.0   4.8   1.8  Iris-virginica\n",
      "139   6.9   3.1   5.4   2.1  Iris-virginica\n",
      "140   6.7   3.1   5.6   2.4  Iris-virginica\n",
      "141   6.9   3.1   5.1   2.3  Iris-virginica\n",
      "142   5.8   2.7   5.1   1.9  Iris-virginica\n",
      "143   6.8   3.2   5.9   2.3  Iris-virginica\n",
      "144   6.7   3.3   5.7   2.5  Iris-virginica\n",
      "145   6.7   3.0   5.2   2.3  Iris-virginica\n",
      "146   6.3   2.5   5.0   1.9  Iris-virginica\n",
      "147   6.5   3.0   5.2   2.0  Iris-virginica\n",
      "148   6.2   3.4   5.4   2.3  Iris-virginica\n",
      "149   5.9   3.0   5.1   1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#DATA CLEANING\n",
    "data=pandas.DataFrame(data)\n",
    "# data=data.replace([\"Iris-setosa\",\"Iris-versicolor\",\"Iris-virginica\"],[0,1,2])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     slen  swid  plen  pwid\n",
      "0     5.1   3.5   1.4   0.2\n",
      "1     4.9   3.0   1.4   0.2\n",
      "2     4.7   3.2   1.3   0.2\n",
      "3     4.6   3.1   1.5   0.2\n",
      "4     5.0   3.6   1.4   0.2\n",
      "5     5.4   3.9   1.7   0.4\n",
      "6     4.6   3.4   1.4   0.3\n",
      "7     5.0   3.4   1.5   0.2\n",
      "8     4.4   2.9   1.4   0.2\n",
      "9     4.9   3.1   1.5   0.1\n",
      "10    5.4   3.7   1.5   0.2\n",
      "11    4.8   3.4   1.6   0.2\n",
      "12    4.8   3.0   1.4   0.1\n",
      "13    4.3   3.0   1.1   0.1\n",
      "14    5.8   4.0   1.2   0.2\n",
      "15    5.7   4.4   1.5   0.4\n",
      "16    5.4   3.9   1.3   0.4\n",
      "17    5.1   3.5   1.4   0.3\n",
      "18    5.7   3.8   1.7   0.3\n",
      "19    5.1   3.8   1.5   0.3\n",
      "20    5.4   3.4   1.7   0.2\n",
      "21    5.1   3.7   1.5   0.4\n",
      "22    4.6   3.6   1.0   0.2\n",
      "23    5.1   3.3   1.7   0.5\n",
      "24    4.8   3.4   1.9   0.2\n",
      "25    5.0   3.0   1.6   0.2\n",
      "26    5.0   3.4   1.6   0.4\n",
      "27    5.2   3.5   1.5   0.2\n",
      "28    5.2   3.4   1.4   0.2\n",
      "29    4.7   3.2   1.6   0.2\n",
      "..    ...   ...   ...   ...\n",
      "120   6.9   3.2   5.7   2.3\n",
      "121   5.6   2.8   4.9   2.0\n",
      "122   7.7   2.8   6.7   2.0\n",
      "123   6.3   2.7   4.9   1.8\n",
      "124   6.7   3.3   5.7   2.1\n",
      "125   7.2   3.2   6.0   1.8\n",
      "126   6.2   2.8   4.8   1.8\n",
      "127   6.1   3.0   4.9   1.8\n",
      "128   6.4   2.8   5.6   2.1\n",
      "129   7.2   3.0   5.8   1.6\n",
      "130   7.4   2.8   6.1   1.9\n",
      "131   7.9   3.8   6.4   2.0\n",
      "132   6.4   2.8   5.6   2.2\n",
      "133   6.3   2.8   5.1   1.5\n",
      "134   6.1   2.6   5.6   1.4\n",
      "135   7.7   3.0   6.1   2.3\n",
      "136   6.3   3.4   5.6   2.4\n",
      "137   6.4   3.1   5.5   1.8\n",
      "138   6.0   3.0   4.8   1.8\n",
      "139   6.9   3.1   5.4   2.1\n",
      "140   6.7   3.1   5.6   2.4\n",
      "141   6.9   3.1   5.1   2.3\n",
      "142   5.8   2.7   5.1   1.9\n",
      "143   6.8   3.2   5.9   2.3\n",
      "144   6.7   3.3   5.7   2.5\n",
      "145   6.7   3.0   5.2   2.3\n",
      "146   6.3   2.5   5.0   1.9\n",
      "147   6.5   3.0   5.2   2.0\n",
      "148   6.2   3.4   5.4   2.3\n",
      "149   5.9   3.0   5.1   1.8\n",
      "\n",
      "[150 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "feature_cols=[\"slen\",\"swid\",\"plen\",\"pwid\"]\n",
    "x=data[feature_cols]\n",
    "x=x.astype(float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "#ONE HOT ENCODING\n",
    "y=data[\"class\"]\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(y)\n",
    "print(integer_encoded)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]]\n",
      "0.0133333333333\n",
      "0.0133333333333\n",
      "accuracy =  99.9866666667 %\n"
     ]
    }
   ],
   "source": [
    "#K-nearest-Neighbour(KNN)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "onehot_encoded = np.array(onehot_encoded)\n",
    "x= np.array(x)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, onehot_encoded, test_size=0.33, random_state=42)\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=2)\n",
    "# Fit the model on the training data.\n",
    "knn.fit(x_train, y_train)\n",
    "# Make point predictions on the test set using the fit model.\n",
    "prediction = knn.predict(x_test)\n",
    "print(prediction)\n",
    "print (metrics.mean_absolute_error(y_test,prediction))\n",
    "print (metrics.mean_squared_error(y_test,prediction))\n",
    "\n",
    "acc = 100 - (metrics.mean_absolute_error(y_test,prediction))\n",
    "print(\"accuracy = \",acc,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n",
      "(150, 3)\n",
      "Train on 100 samples, validate on 50 samples\n",
      "Epoch 1/1000\n",
      "100/100 [==============================] - 0s 450us/step - loss: 0.4349 - acc: 0.3500 - val_loss: 0.4383 - val_acc: 0.3000\n",
      "Epoch 2/1000\n",
      "100/100 [==============================] - 0s 46us/step - loss: 0.4334 - acc: 0.3500 - val_loss: 0.4369 - val_acc: 0.3000\n",
      "Epoch 3/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.4319 - acc: 0.3500 - val_loss: 0.4355 - val_acc: 0.3000\n",
      "Epoch 4/1000\n",
      "100/100 [==============================] - 0s 68us/step - loss: 0.4307 - acc: 0.3500 - val_loss: 0.4343 - val_acc: 0.3000\n",
      "Epoch 5/1000\n",
      "100/100 [==============================] - 0s 88us/step - loss: 0.4296 - acc: 0.3500 - val_loss: 0.4331 - val_acc: 0.3000\n",
      "Epoch 6/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.4285 - acc: 0.3500 - val_loss: 0.4320 - val_acc: 0.3000\n",
      "Epoch 7/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.4276 - acc: 0.3500 - val_loss: 0.4310 - val_acc: 0.3000\n",
      "Epoch 8/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.4268 - acc: 0.3500 - val_loss: 0.4301 - val_acc: 0.3000\n",
      "Epoch 9/1000\n",
      "100/100 [==============================] - 0s 69us/step - loss: 0.4261 - acc: 0.3500 - val_loss: 0.4292 - val_acc: 0.3000\n",
      "Epoch 10/1000\n",
      "100/100 [==============================] - 0s 47us/step - loss: 0.4254 - acc: 0.3500 - val_loss: 0.4284 - val_acc: 0.3000\n",
      "Epoch 11/1000\n",
      "100/100 [==============================] - 0s 73us/step - loss: 0.4247 - acc: 0.3500 - val_loss: 0.4276 - val_acc: 0.3000\n",
      "Epoch 12/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.4240 - acc: 0.3500 - val_loss: 0.4269 - val_acc: 0.3000\n",
      "Epoch 13/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.4233 - acc: 0.3500 - val_loss: 0.4262 - val_acc: 0.3000\n",
      "Epoch 14/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.4227 - acc: 0.3500 - val_loss: 0.4255 - val_acc: 0.3000\n",
      "Epoch 15/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.4220 - acc: 0.3500 - val_loss: 0.4247 - val_acc: 0.3000\n",
      "Epoch 16/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.4214 - acc: 0.3500 - val_loss: 0.4239 - val_acc: 0.3200\n",
      "Epoch 17/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.4207 - acc: 0.3700 - val_loss: 0.4230 - val_acc: 0.3200\n",
      "Epoch 18/1000\n",
      "100/100 [==============================] - 0s 82us/step - loss: 0.4200 - acc: 0.3900 - val_loss: 0.4222 - val_acc: 0.3600\n",
      "Epoch 19/1000\n",
      "100/100 [==============================] - 0s 76us/step - loss: 0.4193 - acc: 0.4300 - val_loss: 0.4213 - val_acc: 0.4600\n",
      "Epoch 20/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.4185 - acc: 0.5100 - val_loss: 0.4204 - val_acc: 0.4800\n",
      "Epoch 21/1000\n",
      "100/100 [==============================] - 0s 48us/step - loss: 0.4178 - acc: 0.5400 - val_loss: 0.4194 - val_acc: 0.5200\n",
      "Epoch 22/1000\n",
      "100/100 [==============================] - 0s 46us/step - loss: 0.4170 - acc: 0.6300 - val_loss: 0.4184 - val_acc: 0.5600\n",
      "Epoch 23/1000\n",
      "100/100 [==============================] - 0s 44us/step - loss: 0.4162 - acc: 0.6200 - val_loss: 0.4174 - val_acc: 0.5800\n",
      "Epoch 24/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.4154 - acc: 0.6400 - val_loss: 0.4163 - val_acc: 0.5800\n",
      "Epoch 25/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.4146 - acc: 0.6300 - val_loss: 0.4153 - val_acc: 0.5800\n",
      "Epoch 26/1000\n",
      "100/100 [==============================] - 0s 46us/step - loss: 0.4137 - acc: 0.6000 - val_loss: 0.4143 - val_acc: 0.5400\n",
      "Epoch 27/1000\n",
      "100/100 [==============================] - 0s 79us/step - loss: 0.4129 - acc: 0.5700 - val_loss: 0.4131 - val_acc: 0.5000\n",
      "Epoch 28/1000\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.4121 - acc: 0.5100 - val_loss: 0.4120 - val_acc: 0.5000\n",
      "Epoch 29/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.4111 - acc: 0.4800 - val_loss: 0.4108 - val_acc: 0.4400\n",
      "Epoch 30/1000\n",
      "100/100 [==============================] - 0s 149us/step - loss: 0.4103 - acc: 0.4500 - val_loss: 0.4097 - val_acc: 0.4200\n",
      "Epoch 31/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 0.4095 - acc: 0.4400 - val_loss: 0.4085 - val_acc: 0.4600\n",
      "Epoch 32/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.4085 - acc: 0.4400 - val_loss: 0.4075 - val_acc: 0.5800\n",
      "Epoch 33/1000\n",
      "100/100 [==============================] - 0s 98us/step - loss: 0.4076 - acc: 0.5200 - val_loss: 0.4064 - val_acc: 0.6200\n",
      "Epoch 34/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.4068 - acc: 0.5900 - val_loss: 0.4054 - val_acc: 0.7000\n",
      "Epoch 35/1000\n",
      "100/100 [==============================] - 0s 42us/step - loss: 0.4059 - acc: 0.6300 - val_loss: 0.4044 - val_acc: 0.7200\n",
      "Epoch 36/1000\n",
      "100/100 [==============================] - 0s 68us/step - loss: 0.4050 - acc: 0.6500 - val_loss: 0.4033 - val_acc: 0.7000\n",
      "Epoch 37/1000\n",
      "100/100 [==============================] - 0s 81us/step - loss: 0.4040 - acc: 0.6600 - val_loss: 0.4022 - val_acc: 0.7000\n",
      "Epoch 38/1000\n",
      "100/100 [==============================] - 0s 41us/step - loss: 0.4031 - acc: 0.6500 - val_loss: 0.4010 - val_acc: 0.7000\n",
      "Epoch 39/1000\n",
      "100/100 [==============================] - 0s 43us/step - loss: 0.4021 - acc: 0.6500 - val_loss: 0.3997 - val_acc: 0.7000\n",
      "Epoch 40/1000\n",
      "100/100 [==============================] - 0s 42us/step - loss: 0.4011 - acc: 0.6500 - val_loss: 0.3984 - val_acc: 0.7000\n",
      "Epoch 41/1000\n",
      "100/100 [==============================] - 0s 74us/step - loss: 0.4001 - acc: 0.6500 - val_loss: 0.3971 - val_acc: 0.7000\n",
      "Epoch 42/1000\n",
      "100/100 [==============================] - 0s 46us/step - loss: 0.3991 - acc: 0.6500 - val_loss: 0.3958 - val_acc: 0.7000\n",
      "Epoch 43/1000\n",
      "100/100 [==============================] - 0s 48us/step - loss: 0.3980 - acc: 0.6500 - val_loss: 0.3945 - val_acc: 0.7000\n",
      "Epoch 44/1000\n",
      "100/100 [==============================] - 0s 39us/step - loss: 0.3969 - acc: 0.6500 - val_loss: 0.3931 - val_acc: 0.7000\n",
      "Epoch 45/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.3958 - acc: 0.6500 - val_loss: 0.3917 - val_acc: 0.7000\n",
      "Epoch 46/1000\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.3947 - acc: 0.6500 - val_loss: 0.3903 - val_acc: 0.7000\n",
      "Epoch 47/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.3936 - acc: 0.6500 - val_loss: 0.3889 - val_acc: 0.7000\n",
      "Epoch 48/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.3925 - acc: 0.6500 - val_loss: 0.3875 - val_acc: 0.7000\n",
      "Epoch 49/1000\n",
      "100/100 [==============================] - 0s 47us/step - loss: 0.3913 - acc: 0.6500 - val_loss: 0.3861 - val_acc: 0.7000\n",
      "Epoch 50/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.3901 - acc: 0.6500 - val_loss: 0.3847 - val_acc: 0.7000\n",
      "Epoch 51/1000\n",
      "100/100 [==============================] - 0s 76us/step - loss: 0.3890 - acc: 0.6500 - val_loss: 0.3832 - val_acc: 0.7000\n",
      "Epoch 52/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.3878 - acc: 0.6500 - val_loss: 0.3817 - val_acc: 0.7000\n",
      "Epoch 53/1000\n",
      "100/100 [==============================] - 0s 78us/step - loss: 0.3865 - acc: 0.6500 - val_loss: 0.3803 - val_acc: 0.7000\n",
      "Epoch 54/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.3853 - acc: 0.6500 - val_loss: 0.3788 - val_acc: 0.7000\n",
      "Epoch 55/1000\n",
      "100/100 [==============================] - 0s 105us/step - loss: 0.3841 - acc: 0.6500 - val_loss: 0.3772 - val_acc: 0.7000\n",
      "Epoch 56/1000\n",
      "100/100 [==============================] - 0s 45us/step - loss: 0.3829 - acc: 0.6500 - val_loss: 0.3757 - val_acc: 0.7000\n",
      "Epoch 57/1000\n",
      "100/100 [==============================] - 0s 44us/step - loss: 0.3814 - acc: 0.6500 - val_loss: 0.3743 - val_acc: 0.7000\n",
      "Epoch 58/1000\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.3802 - acc: 0.6500 - val_loss: 0.3727 - val_acc: 0.7000\n",
      "Epoch 59/1000\n",
      "100/100 [==============================] - 0s 89us/step - loss: 0.3788 - acc: 0.6500 - val_loss: 0.3712 - val_acc: 0.7000\n",
      "Epoch 60/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.3774 - acc: 0.6500 - val_loss: 0.3695 - val_acc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.3760 - acc: 0.6500 - val_loss: 0.3678 - val_acc: 0.7000\n",
      "Epoch 62/1000\n",
      "100/100 [==============================] - 0s 77us/step - loss: 0.3744 - acc: 0.6500 - val_loss: 0.3660 - val_acc: 0.7000\n",
      "Epoch 63/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3635 - acc: 0.700 - 0s 72us/step - loss: 0.3729 - acc: 0.6500 - val_loss: 0.3642 - val_acc: 0.7000\n",
      "Epoch 64/1000\n",
      "100/100 [==============================] - 0s 112us/step - loss: 0.3712 - acc: 0.6500 - val_loss: 0.3624 - val_acc: 0.7000\n",
      "Epoch 65/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.3696 - acc: 0.6500 - val_loss: 0.3604 - val_acc: 0.7000\n",
      "Epoch 66/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.3679 - acc: 0.6500 - val_loss: 0.3584 - val_acc: 0.7000\n",
      "Epoch 67/1000\n",
      "100/100 [==============================] - 0s 45us/step - loss: 0.3662 - acc: 0.6500 - val_loss: 0.3564 - val_acc: 0.7000\n",
      "Epoch 68/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.3643 - acc: 0.6500 - val_loss: 0.3543 - val_acc: 0.7000\n",
      "Epoch 69/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.3625 - acc: 0.6500 - val_loss: 0.3521 - val_acc: 0.7000\n",
      "Epoch 70/1000\n",
      "100/100 [==============================] - 0s 47us/step - loss: 0.3605 - acc: 0.6500 - val_loss: 0.3498 - val_acc: 0.7000\n",
      "Epoch 71/1000\n",
      "100/100 [==============================] - 0s 97us/step - loss: 0.3586 - acc: 0.6500 - val_loss: 0.3475 - val_acc: 0.7000\n",
      "Epoch 72/1000\n",
      "100/100 [==============================] - 0s 42us/step - loss: 0.3566 - acc: 0.6500 - val_loss: 0.3452 - val_acc: 0.7000\n",
      "Epoch 73/1000\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.3545 - acc: 0.6500 - val_loss: 0.3428 - val_acc: 0.7000\n",
      "Epoch 74/1000\n",
      "100/100 [==============================] - 0s 45us/step - loss: 0.3525 - acc: 0.6500 - val_loss: 0.3404 - val_acc: 0.7000\n",
      "Epoch 75/1000\n",
      "100/100 [==============================] - 0s 48us/step - loss: 0.3504 - acc: 0.6500 - val_loss: 0.3380 - val_acc: 0.7000\n",
      "Epoch 76/1000\n",
      "100/100 [==============================] - 0s 89us/step - loss: 0.3482 - acc: 0.6500 - val_loss: 0.3356 - val_acc: 0.7000\n",
      "Epoch 77/1000\n",
      "100/100 [==============================] - 0s 46us/step - loss: 0.3463 - acc: 0.6500 - val_loss: 0.3332 - val_acc: 0.7000\n",
      "Epoch 78/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.3442 - acc: 0.6500 - val_loss: 0.3309 - val_acc: 0.7000\n",
      "Epoch 79/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.3420 - acc: 0.6500 - val_loss: 0.3285 - val_acc: 0.7000\n",
      "Epoch 80/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.3402 - acc: 0.6500 - val_loss: 0.3261 - val_acc: 0.7000\n",
      "Epoch 81/1000\n",
      "100/100 [==============================] - 0s 49us/step - loss: 0.3380 - acc: 0.6500 - val_loss: 0.3238 - val_acc: 0.7000\n",
      "Epoch 82/1000\n",
      "100/100 [==============================] - 0s 63us/step - loss: 0.3361 - acc: 0.6500 - val_loss: 0.3215 - val_acc: 0.7000\n",
      "Epoch 83/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.3339 - acc: 0.6500 - val_loss: 0.3193 - val_acc: 0.7000\n",
      "Epoch 84/1000\n",
      "100/100 [==============================] - 0s 94us/step - loss: 0.3321 - acc: 0.6500 - val_loss: 0.3170 - val_acc: 0.7000\n",
      "Epoch 85/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.3303 - acc: 0.6500 - val_loss: 0.3148 - val_acc: 0.7000\n",
      "Epoch 86/1000\n",
      "100/100 [==============================] - 0s 78us/step - loss: 0.3283 - acc: 0.6500 - val_loss: 0.3127 - val_acc: 0.7000\n",
      "Epoch 87/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.3265 - acc: 0.6500 - val_loss: 0.3106 - val_acc: 0.7000\n",
      "Epoch 88/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.3248 - acc: 0.6500 - val_loss: 0.3085 - val_acc: 0.7000\n",
      "Epoch 89/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 0.3229 - acc: 0.6500 - val_loss: 0.3064 - val_acc: 0.7000\n",
      "Epoch 90/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.3213 - acc: 0.6500 - val_loss: 0.3044 - val_acc: 0.7000\n",
      "Epoch 91/1000\n",
      "100/100 [==============================] - 0s 63us/step - loss: 0.3195 - acc: 0.6500 - val_loss: 0.3024 - val_acc: 0.7000\n",
      "Epoch 92/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3158 - acc: 0.657 - 0s 115us/step - loss: 0.3178 - acc: 0.6500 - val_loss: 0.3004 - val_acc: 0.7000\n",
      "Epoch 93/1000\n",
      "100/100 [==============================] - 0s 43us/step - loss: 0.3162 - acc: 0.6500 - val_loss: 0.2984 - val_acc: 0.7000\n",
      "Epoch 94/1000\n",
      "100/100 [==============================] - 0s 68us/step - loss: 0.3146 - acc: 0.6500 - val_loss: 0.2965 - val_acc: 0.7000\n",
      "Epoch 95/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.3129 - acc: 0.6500 - val_loss: 0.2947 - val_acc: 0.7000\n",
      "Epoch 96/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.3114 - acc: 0.6500 - val_loss: 0.2928 - val_acc: 0.7000\n",
      "Epoch 97/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.3099 - acc: 0.6500 - val_loss: 0.2911 - val_acc: 0.7000\n",
      "Epoch 98/1000\n",
      "100/100 [==============================] - 0s 79us/step - loss: 0.3084 - acc: 0.6500 - val_loss: 0.2893 - val_acc: 0.7000\n",
      "Epoch 99/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.3069 - acc: 0.6500 - val_loss: 0.2876 - val_acc: 0.7000\n",
      "Epoch 100/1000\n",
      "100/100 [==============================] - 0s 89us/step - loss: 0.3054 - acc: 0.6500 - val_loss: 0.2859 - val_acc: 0.7000\n",
      "Epoch 101/1000\n",
      "100/100 [==============================] - 0s 47us/step - loss: 0.3040 - acc: 0.6500 - val_loss: 0.2842 - val_acc: 0.7000\n",
      "Epoch 102/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.3025 - acc: 0.6500 - val_loss: 0.2826 - val_acc: 0.7000\n",
      "Epoch 103/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.3011 - acc: 0.6500 - val_loss: 0.2809 - val_acc: 0.7000\n",
      "Epoch 104/1000\n",
      "100/100 [==============================] - 0s 81us/step - loss: 0.2997 - acc: 0.6500 - val_loss: 0.2793 - val_acc: 0.7000\n",
      "Epoch 105/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.2983 - acc: 0.6500 - val_loss: 0.2777 - val_acc: 0.7000\n",
      "Epoch 106/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.2971 - acc: 0.6500 - val_loss: 0.2761 - val_acc: 0.7000\n",
      "Epoch 107/1000\n",
      "100/100 [==============================] - 0s 74us/step - loss: 0.2955 - acc: 0.6500 - val_loss: 0.2746 - val_acc: 0.7000\n",
      "Epoch 108/1000\n",
      "100/100 [==============================] - 0s 82us/step - loss: 0.2944 - acc: 0.6500 - val_loss: 0.2731 - val_acc: 0.7000\n",
      "Epoch 109/1000\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.2931 - acc: 0.6500 - val_loss: 0.2716 - val_acc: 0.7000\n",
      "Epoch 110/1000\n",
      "100/100 [==============================] - 0s 82us/step - loss: 0.2917 - acc: 0.6500 - val_loss: 0.2701 - val_acc: 0.7000\n",
      "Epoch 111/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.2905 - acc: 0.6500 - val_loss: 0.2687 - val_acc: 0.7000\n",
      "Epoch 112/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.2893 - acc: 0.6500 - val_loss: 0.2673 - val_acc: 0.7000\n",
      "Epoch 113/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.2882 - acc: 0.6500 - val_loss: 0.2659 - val_acc: 0.7000\n",
      "Epoch 114/1000\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.2869 - acc: 0.6500 - val_loss: 0.2646 - val_acc: 0.7000\n",
      "Epoch 115/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.2859 - acc: 0.6500 - val_loss: 0.2633 - val_acc: 0.7000\n",
      "Epoch 116/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.2847 - acc: 0.6500 - val_loss: 0.2620 - val_acc: 0.7000\n",
      "Epoch 117/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.2835 - acc: 0.6500 - val_loss: 0.2608 - val_acc: 0.7000\n",
      "Epoch 118/1000\n",
      "100/100 [==============================] - 0s 49us/step - loss: 0.2824 - acc: 0.6500 - val_loss: 0.2595 - val_acc: 0.7000\n",
      "Epoch 119/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.2813 - acc: 0.6500 - val_loss: 0.2583 - val_acc: 0.7000\n",
      "Epoch 120/1000\n",
      "100/100 [==============================] - 0s 69us/step - loss: 0.2803 - acc: 0.6500 - val_loss: 0.2571 - val_acc: 0.7000\n",
      "Epoch 121/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.2792 - acc: 0.6500 - val_loss: 0.2560 - val_acc: 0.7000\n",
      "Epoch 122/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.2783 - acc: 0.6500 - val_loss: 0.2548 - val_acc: 0.7000\n",
      "Epoch 123/1000\n",
      "100/100 [==============================] - 0s 167us/step - loss: 0.2772 - acc: 0.6500 - val_loss: 0.2537 - val_acc: 0.7000\n",
      "Epoch 124/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.2763 - acc: 0.6500 - val_loss: 0.2526 - val_acc: 0.7000\n",
      "Epoch 125/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.2753 - acc: 0.6500 - val_loss: 0.2515 - val_acc: 0.7000\n",
      "Epoch 126/1000\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.2743 - acc: 0.6500 - val_loss: 0.2505 - val_acc: 0.7000\n",
      "Epoch 127/1000\n",
      "100/100 [==============================] - 0s 47us/step - loss: 0.2734 - acc: 0.6500 - val_loss: 0.2495 - val_acc: 0.7000\n",
      "Epoch 128/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.2725 - acc: 0.6500 - val_loss: 0.2484 - val_acc: 0.7000\n",
      "Epoch 129/1000\n",
      "100/100 [==============================] - 0s 42us/step - loss: 0.2717 - acc: 0.6500 - val_loss: 0.2475 - val_acc: 0.7000\n",
      "Epoch 130/1000\n",
      "100/100 [==============================] - 0s 86us/step - loss: 0.2708 - acc: 0.6500 - val_loss: 0.2465 - val_acc: 0.7000\n",
      "Epoch 131/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.2700 - acc: 0.6500 - val_loss: 0.2456 - val_acc: 0.7000\n",
      "Epoch 132/1000\n",
      "100/100 [==============================] - 0s 148us/step - loss: 0.2691 - acc: 0.6500 - val_loss: 0.2446 - val_acc: 0.7000\n",
      "Epoch 133/1000\n",
      "100/100 [==============================] - 0s 66us/step - loss: 0.2685 - acc: 0.6500 - val_loss: 0.2438 - val_acc: 0.7000\n",
      "Epoch 134/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.2676 - acc: 0.6500 - val_loss: 0.2429 - val_acc: 0.7000\n",
      "Epoch 135/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.2669 - acc: 0.6500 - val_loss: 0.2421 - val_acc: 0.7000\n",
      "Epoch 136/1000\n",
      "100/100 [==============================] - 0s 95us/step - loss: 0.2662 - acc: 0.6500 - val_loss: 0.2413 - val_acc: 0.7000\n",
      "Epoch 137/1000\n",
      "100/100 [==============================] - 0s 47us/step - loss: 0.2654 - acc: 0.6500 - val_loss: 0.2405 - val_acc: 0.7000\n",
      "Epoch 138/1000\n",
      "100/100 [==============================] - 0s 119us/step - loss: 0.2647 - acc: 0.6500 - val_loss: 0.2397 - val_acc: 0.7000\n",
      "Epoch 139/1000\n",
      "100/100 [==============================] - 0s 74us/step - loss: 0.2640 - acc: 0.6500 - val_loss: 0.2390 - val_acc: 0.7000\n",
      "Epoch 140/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.2634 - acc: 0.6500 - val_loss: 0.2382 - val_acc: 0.7000\n",
      "Epoch 141/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.2628 - acc: 0.6500 - val_loss: 0.2375 - val_acc: 0.7000\n",
      "Epoch 142/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.2621 - acc: 0.6500 - val_loss: 0.2368 - val_acc: 0.7000\n",
      "Epoch 143/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.2615 - acc: 0.6500 - val_loss: 0.2361 - val_acc: 0.7000\n",
      "Epoch 144/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.2609 - acc: 0.6500 - val_loss: 0.2355 - val_acc: 0.7000\n",
      "Epoch 145/1000\n",
      "100/100 [==============================] - 0s 43us/step - loss: 0.2602 - acc: 0.6500 - val_loss: 0.2348 - val_acc: 0.7000\n",
      "Epoch 146/1000\n",
      "100/100 [==============================] - 0s 79us/step - loss: 0.2597 - acc: 0.6500 - val_loss: 0.2342 - val_acc: 0.7000\n",
      "Epoch 147/1000\n",
      "100/100 [==============================] - 0s 43us/step - loss: 0.2591 - acc: 0.6500 - val_loss: 0.2335 - val_acc: 0.7000\n",
      "Epoch 148/1000\n",
      "100/100 [==============================] - 0s 84us/step - loss: 0.2585 - acc: 0.6500 - val_loss: 0.2329 - val_acc: 0.7000\n",
      "Epoch 149/1000\n",
      "100/100 [==============================] - 0s 43us/step - loss: 0.2579 - acc: 0.6500 - val_loss: 0.2323 - val_acc: 0.7000\n",
      "Epoch 150/1000\n",
      "100/100 [==============================] - 0s 68us/step - loss: 0.2573 - acc: 0.6500 - val_loss: 0.2317 - val_acc: 0.7000\n",
      "Epoch 151/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.2568 - acc: 0.6500 - val_loss: 0.2311 - val_acc: 0.7000\n",
      "Epoch 152/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.2562 - acc: 0.6500 - val_loss: 0.2306 - val_acc: 0.7000\n",
      "Epoch 153/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.2557 - acc: 0.6500 - val_loss: 0.2300 - val_acc: 0.7000\n",
      "Epoch 154/1000\n",
      "100/100 [==============================] - 0s 89us/step - loss: 0.2551 - acc: 0.6500 - val_loss: 0.2294 - val_acc: 0.7000\n",
      "Epoch 155/1000\n",
      "100/100 [==============================] - 0s 113us/step - loss: 0.2546 - acc: 0.6500 - val_loss: 0.2288 - val_acc: 0.7000\n",
      "Epoch 156/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.2541 - acc: 0.6500 - val_loss: 0.2282 - val_acc: 0.7000\n",
      "Epoch 157/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.2535 - acc: 0.6500 - val_loss: 0.2277 - val_acc: 0.7000\n",
      "Epoch 158/1000\n",
      "100/100 [==============================] - 0s 103us/step - loss: 0.2530 - acc: 0.6500 - val_loss: 0.2271 - val_acc: 0.7000\n",
      "Epoch 159/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.2524 - acc: 0.6500 - val_loss: 0.2265 - val_acc: 0.7000\n",
      "Epoch 160/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 0.2519 - acc: 0.6500 - val_loss: 0.2260 - val_acc: 0.7000\n",
      "Epoch 161/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.2513 - acc: 0.6500 - val_loss: 0.2255 - val_acc: 0.7000\n",
      "Epoch 162/1000\n",
      "100/100 [==============================] - 0s 83us/step - loss: 0.2508 - acc: 0.6500 - val_loss: 0.2249 - val_acc: 0.7000\n",
      "Epoch 163/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.2502 - acc: 0.6500 - val_loss: 0.2244 - val_acc: 0.7000\n",
      "Epoch 164/1000\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.2497 - acc: 0.6500 - val_loss: 0.2238 - val_acc: 0.7000\n",
      "Epoch 165/1000\n",
      "100/100 [==============================] - 0s 79us/step - loss: 0.2491 - acc: 0.6500 - val_loss: 0.2232 - val_acc: 0.7000\n",
      "Epoch 166/1000\n",
      "100/100 [==============================] - 0s 86us/step - loss: 0.2485 - acc: 0.6500 - val_loss: 0.2226 - val_acc: 0.7000\n",
      "Epoch 167/1000\n",
      "100/100 [==============================] - 0s 69us/step - loss: 0.2480 - acc: 0.6500 - val_loss: 0.2221 - val_acc: 0.7000\n",
      "Epoch 168/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.2474 - acc: 0.6500 - val_loss: 0.2215 - val_acc: 0.7000\n",
      "Epoch 169/1000\n",
      "100/100 [==============================] - 0s 63us/step - loss: 0.2468 - acc: 0.6500 - val_loss: 0.2209 - val_acc: 0.7000\n",
      "Epoch 170/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.2462 - acc: 0.6500 - val_loss: 0.2203 - val_acc: 0.7000\n",
      "Epoch 171/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.2456 - acc: 0.6500 - val_loss: 0.2198 - val_acc: 0.7000\n",
      "Epoch 172/1000\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.2449 - acc: 0.6500 - val_loss: 0.2192 - val_acc: 0.7000\n",
      "Epoch 173/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.2443 - acc: 0.6500 - val_loss: 0.2186 - val_acc: 0.7000\n",
      "Epoch 174/1000\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.2437 - acc: 0.6500 - val_loss: 0.2180 - val_acc: 0.7000\n",
      "Epoch 175/1000\n",
      "100/100 [==============================] - 0s 48us/step - loss: 0.2431 - acc: 0.6500 - val_loss: 0.2173 - val_acc: 0.7000\n",
      "Epoch 176/1000\n",
      "100/100 [==============================] - 0s 83us/step - loss: 0.2424 - acc: 0.6500 - val_loss: 0.2167 - val_acc: 0.7000\n",
      "Epoch 177/1000\n",
      "100/100 [==============================] - 0s 97us/step - loss: 0.2417 - acc: 0.6500 - val_loss: 0.2161 - val_acc: 0.7000\n",
      "Epoch 178/1000\n",
      "100/100 [==============================] - 0s 69us/step - loss: 0.2410 - acc: 0.6500 - val_loss: 0.2154 - val_acc: 0.7000\n",
      "Epoch 179/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.2403 - acc: 0.6500 - val_loss: 0.2148 - val_acc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/1000\n",
      "100/100 [==============================] - 0s 68us/step - loss: 0.2396 - acc: 0.6500 - val_loss: 0.2142 - val_acc: 0.7000\n",
      "Epoch 181/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.2389 - acc: 0.6500 - val_loss: 0.2135 - val_acc: 0.7000\n",
      "Epoch 182/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.2382 - acc: 0.6500 - val_loss: 0.2128 - val_acc: 0.7000\n",
      "Epoch 183/1000\n",
      "100/100 [==============================] - 0s 49us/step - loss: 0.2375 - acc: 0.6500 - val_loss: 0.2121 - val_acc: 0.7000\n",
      "Epoch 184/1000\n",
      "100/100 [==============================] - 0s 104us/step - loss: 0.2368 - acc: 0.6500 - val_loss: 0.2114 - val_acc: 0.7000\n",
      "Epoch 185/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.2360 - acc: 0.6500 - val_loss: 0.2107 - val_acc: 0.7000\n",
      "Epoch 186/1000\n",
      "100/100 [==============================] - 0s 69us/step - loss: 0.2354 - acc: 0.6500 - val_loss: 0.2100 - val_acc: 0.7000\n",
      "Epoch 187/1000\n",
      "100/100 [==============================] - 0s 47us/step - loss: 0.2345 - acc: 0.6500 - val_loss: 0.2093 - val_acc: 0.7000\n",
      "Epoch 188/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.2338 - acc: 0.6500 - val_loss: 0.2086 - val_acc: 0.7000\n",
      "Epoch 189/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.2331 - acc: 0.6500 - val_loss: 0.2079 - val_acc: 0.7000\n",
      "Epoch 190/1000\n",
      "100/100 [==============================] - 0s 49us/step - loss: 0.2323 - acc: 0.6500 - val_loss: 0.2071 - val_acc: 0.7000\n",
      "Epoch 191/1000\n",
      "100/100 [==============================] - 0s 72us/step - loss: 0.2314 - acc: 0.6500 - val_loss: 0.2064 - val_acc: 0.7000\n",
      "Epoch 192/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2458 - acc: 0.614 - 0s 68us/step - loss: 0.2307 - acc: 0.6500 - val_loss: 0.2057 - val_acc: 0.7000\n",
      "Epoch 193/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.2299 - acc: 0.6500 - val_loss: 0.2049 - val_acc: 0.7000\n",
      "Epoch 194/1000\n",
      "100/100 [==============================] - 0s 72us/step - loss: 0.2291 - acc: 0.6500 - val_loss: 0.2042 - val_acc: 0.7000\n",
      "Epoch 195/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.2284 - acc: 0.6500 - val_loss: 0.2034 - val_acc: 0.7000\n",
      "Epoch 196/1000\n",
      "100/100 [==============================] - 0s 72us/step - loss: 0.2276 - acc: 0.6500 - val_loss: 0.2027 - val_acc: 0.7000\n",
      "Epoch 197/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.2268 - acc: 0.6500 - val_loss: 0.2019 - val_acc: 0.7000\n",
      "Epoch 198/1000\n",
      "100/100 [==============================] - 0s 86us/step - loss: 0.2259 - acc: 0.6500 - val_loss: 0.2011 - val_acc: 0.7000\n",
      "Epoch 199/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.2251 - acc: 0.6500 - val_loss: 0.2003 - val_acc: 0.7000\n",
      "Epoch 200/1000\n",
      "100/100 [==============================] - 0s 119us/step - loss: 0.2242 - acc: 0.6500 - val_loss: 0.1995 - val_acc: 0.7000\n",
      "Epoch 201/1000\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.2233 - acc: 0.6500 - val_loss: 0.1987 - val_acc: 0.7000\n",
      "Epoch 202/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.2224 - acc: 0.6500 - val_loss: 0.1979 - val_acc: 0.7000\n",
      "Epoch 203/1000\n",
      "100/100 [==============================] - 0s 68us/step - loss: 0.2216 - acc: 0.6500 - val_loss: 0.1971 - val_acc: 0.7000\n",
      "Epoch 204/1000\n",
      "100/100 [==============================] - 0s 63us/step - loss: 0.2207 - acc: 0.6500 - val_loss: 0.1962 - val_acc: 0.7000\n",
      "Epoch 205/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.2198 - acc: 0.6500 - val_loss: 0.1954 - val_acc: 0.7000\n",
      "Epoch 206/1000\n",
      "100/100 [==============================] - 0s 91us/step - loss: 0.2189 - acc: 0.6500 - val_loss: 0.1946 - val_acc: 0.7200\n",
      "Epoch 207/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2054 - acc: 0.685 - 0s 76us/step - loss: 0.2180 - acc: 0.6500 - val_loss: 0.1938 - val_acc: 0.7200\n",
      "Epoch 208/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.2172 - acc: 0.6600 - val_loss: 0.1929 - val_acc: 0.7200\n",
      "Epoch 209/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.2161 - acc: 0.6700 - val_loss: 0.1920 - val_acc: 0.7200\n",
      "Epoch 210/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.2153 - acc: 0.6700 - val_loss: 0.1911 - val_acc: 0.7200\n",
      "Epoch 211/1000\n",
      "100/100 [==============================] - 0s 73us/step - loss: 0.2142 - acc: 0.6800 - val_loss: 0.1903 - val_acc: 0.7200\n",
      "Epoch 212/1000\n",
      "100/100 [==============================] - 0s 47us/step - loss: 0.2132 - acc: 0.6900 - val_loss: 0.1894 - val_acc: 0.7400\n",
      "Epoch 213/1000\n",
      "100/100 [==============================] - 0s 77us/step - loss: 0.2122 - acc: 0.6900 - val_loss: 0.1885 - val_acc: 0.7400\n",
      "Epoch 214/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.2112 - acc: 0.6900 - val_loss: 0.1876 - val_acc: 0.7800\n",
      "Epoch 215/1000\n",
      "100/100 [==============================] - 0s 69us/step - loss: 0.2101 - acc: 0.7000 - val_loss: 0.1866 - val_acc: 0.7800\n",
      "Epoch 216/1000\n",
      "100/100 [==============================] - 0s 72us/step - loss: 0.2090 - acc: 0.7200 - val_loss: 0.1856 - val_acc: 0.7800\n",
      "Epoch 217/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.2078 - acc: 0.7300 - val_loss: 0.1847 - val_acc: 0.8000\n",
      "Epoch 218/1000\n",
      "100/100 [==============================] - 0s 68us/step - loss: 0.2067 - acc: 0.7400 - val_loss: 0.1836 - val_acc: 0.8200\n",
      "Epoch 219/1000\n",
      "100/100 [==============================] - 0s 46us/step - loss: 0.2055 - acc: 0.7400 - val_loss: 0.1826 - val_acc: 0.8200\n",
      "Epoch 220/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.2044 - acc: 0.7700 - val_loss: 0.1815 - val_acc: 0.8400\n",
      "Epoch 221/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.2031 - acc: 0.8000 - val_loss: 0.1804 - val_acc: 0.8600\n",
      "Epoch 222/1000\n",
      "100/100 [==============================] - 0s 97us/step - loss: 0.2018 - acc: 0.8000 - val_loss: 0.1793 - val_acc: 0.8600\n",
      "Epoch 223/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.2004 - acc: 0.8000 - val_loss: 0.1781 - val_acc: 0.8600\n",
      "Epoch 224/1000\n",
      "100/100 [==============================] - 0s 41us/step - loss: 0.1990 - acc: 0.8200 - val_loss: 0.1769 - val_acc: 0.9000\n",
      "Epoch 225/1000\n",
      "100/100 [==============================] - 0s 83us/step - loss: 0.1976 - acc: 0.8200 - val_loss: 0.1757 - val_acc: 0.9200\n",
      "Epoch 226/1000\n",
      "100/100 [==============================] - 0s 46us/step - loss: 0.1961 - acc: 0.8500 - val_loss: 0.1745 - val_acc: 0.9200\n",
      "Epoch 227/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.1947 - acc: 0.8700 - val_loss: 0.1733 - val_acc: 0.9400\n",
      "Epoch 228/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.1930 - acc: 0.8700 - val_loss: 0.1720 - val_acc: 0.9400\n",
      "Epoch 229/1000\n",
      "100/100 [==============================] - 0s 69us/step - loss: 0.1916 - acc: 0.8800 - val_loss: 0.1708 - val_acc: 0.9400\n",
      "Epoch 230/1000\n",
      "100/100 [==============================] - 0s 47us/step - loss: 0.1902 - acc: 0.8900 - val_loss: 0.1696 - val_acc: 0.9600\n",
      "Epoch 231/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.1887 - acc: 0.9100 - val_loss: 0.1684 - val_acc: 0.9600\n",
      "Epoch 232/1000\n",
      "100/100 [==============================] - 0s 84us/step - loss: 0.1873 - acc: 0.9100 - val_loss: 0.1672 - val_acc: 0.9600\n",
      "Epoch 233/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.1859 - acc: 0.9100 - val_loss: 0.1660 - val_acc: 0.9600\n",
      "Epoch 234/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.1846 - acc: 0.9200 - val_loss: 0.1648 - val_acc: 0.9800\n",
      "Epoch 235/1000\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.1831 - acc: 0.9300 - val_loss: 0.1636 - val_acc: 0.9800\n",
      "Epoch 236/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.1817 - acc: 0.9400 - val_loss: 0.1623 - val_acc: 0.9800\n",
      "Epoch 237/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.1805 - acc: 0.9400 - val_loss: 0.1612 - val_acc: 0.9800\n",
      "Epoch 238/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.1790 - acc: 0.9400 - val_loss: 0.1599 - val_acc: 0.9800\n",
      "Epoch 239/1000\n",
      "100/100 [==============================] - 0s 119us/step - loss: 0.1776 - acc: 0.9400 - val_loss: 0.1585 - val_acc: 0.9800\n",
      "Epoch 240/1000\n",
      "100/100 [==============================] - 0s 102us/step - loss: 0.1761 - acc: 0.9400 - val_loss: 0.1571 - val_acc: 0.9800\n",
      "Epoch 241/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.1748 - acc: 0.9400 - val_loss: 0.1559 - val_acc: 0.9800\n",
      "Epoch 242/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.1737 - acc: 0.9400 - val_loss: 0.1546 - val_acc: 0.9800\n",
      "Epoch 243/1000\n",
      "100/100 [==============================] - 0s 97us/step - loss: 0.1724 - acc: 0.9400 - val_loss: 0.1533 - val_acc: 0.9800\n",
      "Epoch 244/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.1710 - acc: 0.9400 - val_loss: 0.1521 - val_acc: 0.9800\n",
      "Epoch 245/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.1695 - acc: 0.9400 - val_loss: 0.1509 - val_acc: 0.9800\n",
      "Epoch 246/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.1681 - acc: 0.9400 - val_loss: 0.1497 - val_acc: 0.9800\n",
      "Epoch 247/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.1672 - acc: 0.9600 - val_loss: 0.1487 - val_acc: 0.9800\n",
      "Epoch 248/1000\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.1655 - acc: 0.9600 - val_loss: 0.1475 - val_acc: 0.9800\n",
      "Epoch 249/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.1642 - acc: 0.9600 - val_loss: 0.1463 - val_acc: 0.9800\n",
      "Epoch 250/1000\n",
      "100/100 [==============================] - 0s 95us/step - loss: 0.1630 - acc: 0.9600 - val_loss: 0.1452 - val_acc: 0.9800\n",
      "Epoch 251/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.1617 - acc: 0.9600 - val_loss: 0.1441 - val_acc: 0.9800\n",
      "Epoch 252/1000\n",
      "100/100 [==============================] - 0s 85us/step - loss: 0.1605 - acc: 0.9600 - val_loss: 0.1429 - val_acc: 0.9800\n",
      "Epoch 253/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.1591 - acc: 0.9600 - val_loss: 0.1418 - val_acc: 0.9800\n",
      "Epoch 254/1000\n",
      "100/100 [==============================] - 0s 104us/step - loss: 0.1578 - acc: 0.9600 - val_loss: 0.1409 - val_acc: 0.9800\n",
      "Epoch 255/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.1567 - acc: 0.9600 - val_loss: 0.1399 - val_acc: 0.9800\n",
      "Epoch 256/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.1554 - acc: 0.9600 - val_loss: 0.1386 - val_acc: 0.9800\n",
      "Epoch 257/1000\n",
      "100/100 [==============================] - 0s 48us/step - loss: 0.1541 - acc: 0.9600 - val_loss: 0.1373 - val_acc: 0.9800\n",
      "Epoch 258/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.1529 - acc: 0.9600 - val_loss: 0.1362 - val_acc: 0.9800\n",
      "Epoch 259/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.1516 - acc: 0.9600 - val_loss: 0.1351 - val_acc: 0.9800\n",
      "Epoch 260/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.1503 - acc: 0.9600 - val_loss: 0.1340 - val_acc: 0.9800\n",
      "Epoch 261/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.1489 - acc: 0.9600 - val_loss: 0.1330 - val_acc: 0.9800\n",
      "Epoch 262/1000\n",
      "100/100 [==============================] - 0s 41us/step - loss: 0.1478 - acc: 0.9600 - val_loss: 0.1321 - val_acc: 0.9800\n",
      "Epoch 263/1000\n",
      "100/100 [==============================] - 0s 104us/step - loss: 0.1467 - acc: 0.9700 - val_loss: 0.1312 - val_acc: 0.9800\n",
      "Epoch 264/1000\n",
      "100/100 [==============================] - 0s 45us/step - loss: 0.1455 - acc: 0.9700 - val_loss: 0.1302 - val_acc: 0.9800\n",
      "Epoch 265/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.1443 - acc: 0.9700 - val_loss: 0.1292 - val_acc: 0.9800\n",
      "Epoch 266/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.1432 - acc: 0.9700 - val_loss: 0.1282 - val_acc: 0.9800\n",
      "Epoch 267/1000\n",
      "100/100 [==============================] - 0s 76us/step - loss: 0.1420 - acc: 0.9700 - val_loss: 0.1271 - val_acc: 0.9800\n",
      "Epoch 268/1000\n",
      "100/100 [==============================] - 0s 112us/step - loss: 0.1409 - acc: 0.9700 - val_loss: 0.1260 - val_acc: 0.9800\n",
      "Epoch 269/1000\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.1396 - acc: 0.9700 - val_loss: 0.1251 - val_acc: 0.9800\n",
      "Epoch 270/1000\n",
      "100/100 [==============================] - 0s 63us/step - loss: 0.1384 - acc: 0.9700 - val_loss: 0.1241 - val_acc: 0.9800\n",
      "Epoch 271/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1348 - acc: 0.971 - 0s 166us/step - loss: 0.1374 - acc: 0.9700 - val_loss: 0.1230 - val_acc: 0.9800\n",
      "Epoch 272/1000\n",
      "100/100 [==============================] - 0s 69us/step - loss: 0.1361 - acc: 0.9700 - val_loss: 0.1222 - val_acc: 0.9800\n",
      "Epoch 273/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.1351 - acc: 0.9700 - val_loss: 0.1214 - val_acc: 0.9600\n",
      "Epoch 274/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1389 - acc: 0.957 - 0s 61us/step - loss: 0.1343 - acc: 0.9700 - val_loss: 0.1204 - val_acc: 0.9600\n",
      "Epoch 275/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.1330 - acc: 0.9700 - val_loss: 0.1190 - val_acc: 0.9800\n",
      "Epoch 276/1000\n",
      "100/100 [==============================] - 0s 82us/step - loss: 0.1318 - acc: 0.9700 - val_loss: 0.1179 - val_acc: 0.9800\n",
      "Epoch 277/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.1308 - acc: 0.9700 - val_loss: 0.1169 - val_acc: 0.9800\n",
      "Epoch 278/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.1297 - acc: 0.9700 - val_loss: 0.1161 - val_acc: 0.9800\n",
      "Epoch 279/1000\n",
      "100/100 [==============================] - 0s 93us/step - loss: 0.1287 - acc: 0.9700 - val_loss: 0.1154 - val_acc: 0.9800\n",
      "Epoch 280/1000\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.1276 - acc: 0.9700 - val_loss: 0.1146 - val_acc: 0.9800\n",
      "Epoch 281/1000\n",
      "100/100 [==============================] - 0s 77us/step - loss: 0.1268 - acc: 0.9700 - val_loss: 0.1138 - val_acc: 0.9600\n",
      "Epoch 282/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.1257 - acc: 0.9800 - val_loss: 0.1127 - val_acc: 0.9800\n",
      "Epoch 283/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.1247 - acc: 0.9700 - val_loss: 0.1117 - val_acc: 0.9800\n",
      "Epoch 284/1000\n",
      "100/100 [==============================] - 0s 126us/step - loss: 0.1237 - acc: 0.9700 - val_loss: 0.1109 - val_acc: 0.9800\n",
      "Epoch 285/1000\n",
      "100/100 [==============================] - 0s 74us/step - loss: 0.1228 - acc: 0.9700 - val_loss: 0.1100 - val_acc: 0.9800\n",
      "Epoch 286/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.1218 - acc: 0.9700 - val_loss: 0.1093 - val_acc: 0.9800\n",
      "Epoch 287/1000\n",
      "100/100 [==============================] - 0s 158us/step - loss: 0.1210 - acc: 0.9700 - val_loss: 0.1088 - val_acc: 0.9600\n",
      "Epoch 288/1000\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.1199 - acc: 0.9700 - val_loss: 0.1080 - val_acc: 0.9600\n",
      "Epoch 289/1000\n",
      "100/100 [==============================] - 0s 73us/step - loss: 0.1190 - acc: 0.9700 - val_loss: 0.1072 - val_acc: 0.9600\n",
      "Epoch 290/1000\n",
      "100/100 [==============================] - 0s 79us/step - loss: 0.1182 - acc: 0.9800 - val_loss: 0.1064 - val_acc: 0.9600\n",
      "Epoch 291/1000\n",
      "100/100 [==============================] - 0s 48us/step - loss: 0.1171 - acc: 0.9700 - val_loss: 0.1054 - val_acc: 0.9800\n",
      "Epoch 292/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.1167 - acc: 0.9700 - val_loss: 0.1044 - val_acc: 0.9800\n",
      "Epoch 293/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.1155 - acc: 0.9700 - val_loss: 0.1037 - val_acc: 0.9800\n",
      "Epoch 294/1000\n",
      "100/100 [==============================] - 0s 73us/step - loss: 0.1148 - acc: 0.9700 - val_loss: 0.1032 - val_acc: 0.9800\n",
      "Epoch 295/1000\n",
      "100/100 [==============================] - 0s 49us/step - loss: 0.1137 - acc: 0.9700 - val_loss: 0.1025 - val_acc: 0.9600\n",
      "Epoch 296/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.1128 - acc: 0.9700 - val_loss: 0.1017 - val_acc: 0.9800\n",
      "Epoch 297/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.1120 - acc: 0.9700 - val_loss: 0.1009 - val_acc: 0.9800\n",
      "Epoch 298/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 76us/step - loss: 0.1111 - acc: 0.9700 - val_loss: 0.1003 - val_acc: 0.9600\n",
      "Epoch 299/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.1103 - acc: 0.9700 - val_loss: 0.0998 - val_acc: 0.9600\n",
      "Epoch 300/1000\n",
      "100/100 [==============================] - 0s 45us/step - loss: 0.1095 - acc: 0.9800 - val_loss: 0.0993 - val_acc: 0.9600\n",
      "Epoch 301/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.1088 - acc: 0.9800 - val_loss: 0.0986 - val_acc: 0.9600\n",
      "Epoch 302/1000\n",
      "100/100 [==============================] - 0s 72us/step - loss: 0.1080 - acc: 0.9800 - val_loss: 0.0976 - val_acc: 0.9600\n",
      "Epoch 303/1000\n",
      "100/100 [==============================] - 0s 76us/step - loss: 0.1071 - acc: 0.9800 - val_loss: 0.0969 - val_acc: 0.9600\n",
      "Epoch 304/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.1064 - acc: 0.9800 - val_loss: 0.0963 - val_acc: 0.9600\n",
      "Epoch 305/1000\n",
      "100/100 [==============================] - 0s 66us/step - loss: 0.1056 - acc: 0.9800 - val_loss: 0.0955 - val_acc: 0.9600\n",
      "Epoch 306/1000\n",
      "100/100 [==============================] - 0s 111us/step - loss: 0.1047 - acc: 0.9700 - val_loss: 0.0945 - val_acc: 0.9800\n",
      "Epoch 307/1000\n",
      "100/100 [==============================] - 0s 83us/step - loss: 0.1042 - acc: 0.9700 - val_loss: 0.0937 - val_acc: 0.9800\n",
      "Epoch 308/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.1035 - acc: 0.9700 - val_loss: 0.0931 - val_acc: 0.9800\n",
      "Epoch 309/1000\n",
      "100/100 [==============================] - 0s 102us/step - loss: 0.1028 - acc: 0.9700 - val_loss: 0.0924 - val_acc: 0.9800\n",
      "Epoch 310/1000\n",
      "100/100 [==============================] - 0s 73us/step - loss: 0.1020 - acc: 0.9700 - val_loss: 0.0918 - val_acc: 0.9800\n",
      "Epoch 311/1000\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.1013 - acc: 0.9700 - val_loss: 0.0915 - val_acc: 0.9600\n",
      "Epoch 312/1000\n",
      "100/100 [==============================] - 0s 49us/step - loss: 0.1001 - acc: 0.9700 - val_loss: 0.0919 - val_acc: 0.9600\n",
      "Epoch 313/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0999 - acc: 0.9800 - val_loss: 0.0928 - val_acc: 0.9400\n",
      "Epoch 314/1000\n",
      "100/100 [==============================] - 0s 49us/step - loss: 0.0998 - acc: 0.9700 - val_loss: 0.0928 - val_acc: 0.9400\n",
      "Epoch 315/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.0993 - acc: 0.9700 - val_loss: 0.0916 - val_acc: 0.9400\n",
      "Epoch 316/1000\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.0982 - acc: 0.9700 - val_loss: 0.0896 - val_acc: 0.9600\n",
      "Epoch 317/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0968 - acc: 0.9800 - val_loss: 0.0880 - val_acc: 0.9600\n",
      "Epoch 318/1000\n",
      "100/100 [==============================] - 0s 63us/step - loss: 0.0967 - acc: 0.9700 - val_loss: 0.0870 - val_acc: 0.9800\n",
      "Epoch 319/1000\n",
      "100/100 [==============================] - 0s 44us/step - loss: 0.0961 - acc: 0.9700 - val_loss: 0.0864 - val_acc: 0.9800\n",
      "Epoch 320/1000\n",
      "100/100 [==============================] - 0s 112us/step - loss: 0.0955 - acc: 0.9700 - val_loss: 0.0858 - val_acc: 0.9800\n",
      "Epoch 321/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0949 - acc: 0.9700 - val_loss: 0.0854 - val_acc: 0.9800\n",
      "Epoch 322/1000\n",
      "100/100 [==============================] - 0s 74us/step - loss: 0.0943 - acc: 0.9700 - val_loss: 0.0853 - val_acc: 0.9600\n",
      "Epoch 323/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.0933 - acc: 0.9700 - val_loss: 0.0851 - val_acc: 0.9600\n",
      "Epoch 324/1000\n",
      "100/100 [==============================] - 0s 86us/step - loss: 0.0926 - acc: 0.9800 - val_loss: 0.0848 - val_acc: 0.9600\n",
      "Epoch 325/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.0920 - acc: 0.9800 - val_loss: 0.0845 - val_acc: 0.9600\n",
      "Epoch 326/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 0.0914 - acc: 0.9800 - val_loss: 0.0841 - val_acc: 0.9600\n",
      "Epoch 327/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.0908 - acc: 0.9800 - val_loss: 0.0835 - val_acc: 0.9600\n",
      "Epoch 328/1000\n",
      "100/100 [==============================] - 0s 75us/step - loss: 0.0902 - acc: 0.9800 - val_loss: 0.0830 - val_acc: 0.9600\n",
      "Epoch 329/1000\n",
      "100/100 [==============================] - 0s 88us/step - loss: 0.0896 - acc: 0.9800 - val_loss: 0.0824 - val_acc: 0.9600\n",
      "Epoch 330/1000\n",
      "100/100 [==============================] - 0s 81us/step - loss: 0.0890 - acc: 0.9800 - val_loss: 0.0818 - val_acc: 0.9600\n",
      "Epoch 331/1000\n",
      "100/100 [==============================] - 0s 149us/step - loss: 0.0885 - acc: 0.9800 - val_loss: 0.0811 - val_acc: 0.9600\n",
      "Epoch 332/1000\n",
      "100/100 [==============================] - 0s 69us/step - loss: 0.0879 - acc: 0.9800 - val_loss: 0.0804 - val_acc: 0.9600\n",
      "Epoch 333/1000\n",
      "100/100 [==============================] - 0s 84us/step - loss: 0.0874 - acc: 0.9800 - val_loss: 0.0797 - val_acc: 0.9600\n",
      "Epoch 334/1000\n",
      "100/100 [==============================] - 0s 106us/step - loss: 0.0869 - acc: 0.9700 - val_loss: 0.0792 - val_acc: 0.9600\n",
      "Epoch 335/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.0863 - acc: 0.9700 - val_loss: 0.0790 - val_acc: 0.9600\n",
      "Epoch 336/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.0857 - acc: 0.9800 - val_loss: 0.0790 - val_acc: 0.9600\n",
      "Epoch 337/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0851 - acc: 0.9800 - val_loss: 0.0789 - val_acc: 0.9600\n",
      "Epoch 338/1000\n",
      "100/100 [==============================] - 0s 73us/step - loss: 0.0847 - acc: 0.9800 - val_loss: 0.0789 - val_acc: 0.9600\n",
      "Epoch 339/1000\n",
      "100/100 [==============================] - 0s 63us/step - loss: 0.0842 - acc: 0.9800 - val_loss: 0.0785 - val_acc: 0.9600\n",
      "Epoch 340/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 0.0837 - acc: 0.9800 - val_loss: 0.0779 - val_acc: 0.9600\n",
      "Epoch 341/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 0.0831 - acc: 0.9800 - val_loss: 0.0772 - val_acc: 0.9600\n",
      "Epoch 342/1000\n",
      "100/100 [==============================] - 0s 72us/step - loss: 0.0833 - acc: 0.9800 - val_loss: 0.0764 - val_acc: 0.9600\n",
      "Epoch 343/1000\n",
      "100/100 [==============================] - 0s 66us/step - loss: 0.0822 - acc: 0.9800 - val_loss: 0.0764 - val_acc: 0.9600\n",
      "Epoch 344/1000\n",
      "100/100 [==============================] - 0s 63us/step - loss: 0.0816 - acc: 0.9800 - val_loss: 0.0761 - val_acc: 0.9600\n",
      "Epoch 345/1000\n",
      "100/100 [==============================] - 0s 81us/step - loss: 0.0811 - acc: 0.9800 - val_loss: 0.0759 - val_acc: 0.9600\n",
      "Epoch 346/1000\n",
      "100/100 [==============================] - 0s 88us/step - loss: 0.0807 - acc: 0.9800 - val_loss: 0.0757 - val_acc: 0.9600\n",
      "Epoch 347/1000\n",
      "100/100 [==============================] - 0s 75us/step - loss: 0.0803 - acc: 0.9800 - val_loss: 0.0751 - val_acc: 0.9600\n",
      "Epoch 348/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0798 - acc: 0.9800 - val_loss: 0.0742 - val_acc: 0.9600\n",
      "Epoch 349/1000\n",
      "100/100 [==============================] - 0s 49us/step - loss: 0.0792 - acc: 0.9800 - val_loss: 0.0730 - val_acc: 0.9600\n",
      "Epoch 350/1000\n",
      "100/100 [==============================] - 0s 97us/step - loss: 0.0790 - acc: 0.9800 - val_loss: 0.0722 - val_acc: 0.9800\n",
      "Epoch 351/1000\n",
      "100/100 [==============================] - 0s 83us/step - loss: 0.0785 - acc: 0.9700 - val_loss: 0.0718 - val_acc: 0.9800\n",
      "Epoch 352/1000\n",
      "100/100 [==============================] - 0s 91us/step - loss: 0.0781 - acc: 0.9700 - val_loss: 0.0716 - val_acc: 0.9600\n",
      "Epoch 353/1000\n",
      "100/100 [==============================] - 0s 88us/step - loss: 0.0775 - acc: 0.9800 - val_loss: 0.0715 - val_acc: 0.9600\n",
      "Epoch 354/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.0772 - acc: 0.9800 - val_loss: 0.0715 - val_acc: 0.9600\n",
      "Epoch 355/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0766 - acc: 0.9800 - val_loss: 0.0711 - val_acc: 0.9600\n",
      "Epoch 356/1000\n",
      "100/100 [==============================] - 0s 66us/step - loss: 0.0761 - acc: 0.9800 - val_loss: 0.0705 - val_acc: 0.9600\n",
      "Epoch 357/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.0758 - acc: 0.9800 - val_loss: 0.0701 - val_acc: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 358/1000\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.0754 - acc: 0.9800 - val_loss: 0.0701 - val_acc: 0.9600\n",
      "Epoch 359/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.0749 - acc: 0.9800 - val_loss: 0.0708 - val_acc: 0.9600\n",
      "Epoch 360/1000\n",
      "100/100 [==============================] - 0s 118us/step - loss: 0.0745 - acc: 0.9800 - val_loss: 0.0712 - val_acc: 0.9600\n",
      "Epoch 361/1000\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.0744 - acc: 0.9700 - val_loss: 0.0714 - val_acc: 0.9400\n",
      "Epoch 362/1000\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.0742 - acc: 0.9700 - val_loss: 0.0708 - val_acc: 0.9600\n",
      "Epoch 363/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0737 - acc: 0.9700 - val_loss: 0.0698 - val_acc: 0.9600\n",
      "Epoch 364/1000\n",
      "100/100 [==============================] - 0s 69us/step - loss: 0.0731 - acc: 0.9800 - val_loss: 0.0689 - val_acc: 0.9600\n",
      "Epoch 365/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0726 - acc: 0.9800 - val_loss: 0.0676 - val_acc: 0.9600\n",
      "Epoch 366/1000\n",
      "100/100 [==============================] - 0s 108us/step - loss: 0.0722 - acc: 0.9800 - val_loss: 0.0667 - val_acc: 0.9600\n",
      "Epoch 367/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.0719 - acc: 0.9700 - val_loss: 0.0661 - val_acc: 0.9800\n",
      "Epoch 368/1000\n",
      "100/100 [==============================] - 0s 74us/step - loss: 0.0717 - acc: 0.9700 - val_loss: 0.0657 - val_acc: 0.9800\n",
      "Epoch 369/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.0713 - acc: 0.9700 - val_loss: 0.0656 - val_acc: 0.9600\n",
      "Epoch 370/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.0708 - acc: 0.9800 - val_loss: 0.0658 - val_acc: 0.9600\n",
      "Epoch 371/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0704 - acc: 0.9800 - val_loss: 0.0662 - val_acc: 0.9600\n",
      "Epoch 372/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0699 - acc: 0.9800 - val_loss: 0.0664 - val_acc: 0.9600\n",
      "Epoch 373/1000\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.0697 - acc: 0.9800 - val_loss: 0.0666 - val_acc: 0.9600\n",
      "Epoch 374/1000\n",
      "100/100 [==============================] - 0s 46us/step - loss: 0.0694 - acc: 0.9800 - val_loss: 0.0662 - val_acc: 0.9600\n",
      "Epoch 375/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.0690 - acc: 0.9800 - val_loss: 0.0655 - val_acc: 0.9600\n",
      "Epoch 376/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.0685 - acc: 0.9800 - val_loss: 0.0644 - val_acc: 0.9600\n",
      "Epoch 377/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.0682 - acc: 0.9800 - val_loss: 0.0635 - val_acc: 0.9600\n",
      "Epoch 378/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.0679 - acc: 0.9800 - val_loss: 0.0629 - val_acc: 0.9800\n",
      "Epoch 379/1000\n",
      "100/100 [==============================] - 0s 98us/step - loss: 0.0679 - acc: 0.9700 - val_loss: 0.0624 - val_acc: 0.9800\n",
      "Epoch 380/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.0675 - acc: 0.9700 - val_loss: 0.0625 - val_acc: 0.9600\n",
      "Epoch 381/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0671 - acc: 0.9800 - val_loss: 0.0630 - val_acc: 0.9600\n",
      "Epoch 382/1000\n",
      "100/100 [==============================] - 0s 44us/step - loss: 0.0667 - acc: 0.9800 - val_loss: 0.0634 - val_acc: 0.9600\n",
      "Epoch 383/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0663 - acc: 0.9800 - val_loss: 0.0633 - val_acc: 0.9600\n",
      "Epoch 384/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.0660 - acc: 0.9800 - val_loss: 0.0631 - val_acc: 0.9600\n",
      "Epoch 385/1000\n",
      "100/100 [==============================] - 0s 97us/step - loss: 0.0656 - acc: 0.9800 - val_loss: 0.0631 - val_acc: 0.9600\n",
      "Epoch 386/1000\n",
      "100/100 [==============================] - 0s 48us/step - loss: 0.0654 - acc: 0.9800 - val_loss: 0.0629 - val_acc: 0.9600\n",
      "Epoch 387/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0650 - acc: 0.9800 - val_loss: 0.0621 - val_acc: 0.9600\n",
      "Epoch 388/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.0646 - acc: 0.9800 - val_loss: 0.0610 - val_acc: 0.9600\n",
      "Epoch 389/1000\n",
      "100/100 [==============================] - 0s 44us/step - loss: 0.0645 - acc: 0.9800 - val_loss: 0.0599 - val_acc: 0.9600\n",
      "Epoch 390/1000\n",
      "100/100 [==============================] - 0s 48us/step - loss: 0.0645 - acc: 0.9700 - val_loss: 0.0595 - val_acc: 0.9800\n",
      "Epoch 391/1000\n",
      "100/100 [==============================] - 0s 88us/step - loss: 0.0640 - acc: 0.9700 - val_loss: 0.0597 - val_acc: 0.9600\n",
      "Epoch 392/1000\n",
      "100/100 [==============================] - 0s 78us/step - loss: 0.0635 - acc: 0.9800 - val_loss: 0.0601 - val_acc: 0.9600\n",
      "Epoch 393/1000\n",
      "100/100 [==============================] - 0s 74us/step - loss: 0.0631 - acc: 0.9800 - val_loss: 0.0607 - val_acc: 0.9600\n",
      "Epoch 394/1000\n",
      "100/100 [==============================] - 0s 116us/step - loss: 0.0630 - acc: 0.9800 - val_loss: 0.0611 - val_acc: 0.9600\n",
      "Epoch 395/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.0627 - acc: 0.9800 - val_loss: 0.0610 - val_acc: 0.9600\n",
      "Epoch 396/1000\n",
      "100/100 [==============================] - 0s 82us/step - loss: 0.0625 - acc: 0.9800 - val_loss: 0.0608 - val_acc: 0.9600\n",
      "Epoch 397/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.0623 - acc: 0.9800 - val_loss: 0.0603 - val_acc: 0.9600\n",
      "Epoch 398/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0596 - acc: 1.000 - 0s 103us/step - loss: 0.0619 - acc: 0.9800 - val_loss: 0.0599 - val_acc: 0.9600\n",
      "Epoch 399/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 0.0616 - acc: 0.9800 - val_loss: 0.0594 - val_acc: 0.9600\n",
      "Epoch 400/1000\n",
      "100/100 [==============================] - 0s 93us/step - loss: 0.0612 - acc: 0.9800 - val_loss: 0.0586 - val_acc: 0.9600\n",
      "Epoch 401/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0611 - acc: 0.9800 - val_loss: 0.0577 - val_acc: 0.9600\n",
      "Epoch 402/1000\n",
      "100/100 [==============================] - 0s 75us/step - loss: 0.0607 - acc: 0.9800 - val_loss: 0.0573 - val_acc: 0.9600\n",
      "Epoch 403/1000\n",
      "100/100 [==============================] - 0s 47us/step - loss: 0.0605 - acc: 0.9800 - val_loss: 0.0572 - val_acc: 0.9600\n",
      "Epoch 404/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.0601 - acc: 0.9800 - val_loss: 0.0575 - val_acc: 0.9600\n",
      "Epoch 405/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0599 - acc: 0.9800 - val_loss: 0.0579 - val_acc: 0.9600\n",
      "Epoch 406/1000\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.0597 - acc: 0.9800 - val_loss: 0.0582 - val_acc: 0.9600\n",
      "Epoch 407/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0648 - acc: 0.971 - 0s 68us/step - loss: 0.0598 - acc: 0.9800 - val_loss: 0.0589 - val_acc: 0.9600\n",
      "Epoch 408/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.0594 - acc: 0.9800 - val_loss: 0.0585 - val_acc: 0.9600\n",
      "Epoch 409/1000\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.0592 - acc: 0.9800 - val_loss: 0.0578 - val_acc: 0.9600\n",
      "Epoch 410/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0588 - acc: 0.9800 - val_loss: 0.0571 - val_acc: 0.9600\n",
      "Epoch 411/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.0584 - acc: 0.9800 - val_loss: 0.0562 - val_acc: 0.9600\n",
      "Epoch 412/1000\n",
      "100/100 [==============================] - 0s 106us/step - loss: 0.0583 - acc: 0.9800 - val_loss: 0.0552 - val_acc: 0.9600\n",
      "Epoch 413/1000\n",
      "100/100 [==============================] - 0s 63us/step - loss: 0.0580 - acc: 0.9800 - val_loss: 0.0548 - val_acc: 0.9600\n",
      "Epoch 414/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.0578 - acc: 0.9800 - val_loss: 0.0549 - val_acc: 0.9600\n",
      "Epoch 415/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.0577 - acc: 0.9800 - val_loss: 0.0553 - val_acc: 0.9600\n",
      "Epoch 416/1000\n",
      "100/100 [==============================] - 0s 72us/step - loss: 0.0573 - acc: 0.9800 - val_loss: 0.0550 - val_acc: 0.9600\n",
      "Epoch 417/1000\n",
      "100/100 [==============================] - 0s 77us/step - loss: 0.0571 - acc: 0.9800 - val_loss: 0.0544 - val_acc: 0.9600\n",
      "Epoch 418/1000\n",
      "100/100 [==============================] - 0s 77us/step - loss: 0.0568 - acc: 0.9800 - val_loss: 0.0542 - val_acc: 0.9600\n",
      "Epoch 419/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.0565 - acc: 0.9800 - val_loss: 0.0541 - val_acc: 0.9600\n",
      "Epoch 420/1000\n",
      "100/100 [==============================] - 0s 48us/step - loss: 0.0564 - acc: 0.9800 - val_loss: 0.0542 - val_acc: 0.9600\n",
      "Epoch 421/1000\n",
      "100/100 [==============================] - 0s 47us/step - loss: 0.0561 - acc: 0.9800 - val_loss: 0.0539 - val_acc: 0.9600\n",
      "Epoch 422/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.0559 - acc: 0.9800 - val_loss: 0.0534 - val_acc: 0.9600\n",
      "Epoch 423/1000\n",
      "100/100 [==============================] - 0s 63us/step - loss: 0.0557 - acc: 0.9800 - val_loss: 0.0528 - val_acc: 0.9600\n",
      "Epoch 424/1000\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.0555 - acc: 0.9800 - val_loss: 0.0525 - val_acc: 0.9600\n",
      "Epoch 425/1000\n",
      "100/100 [==============================] - 0s 47us/step - loss: 0.0553 - acc: 0.9800 - val_loss: 0.0521 - val_acc: 0.9600\n",
      "Epoch 426/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.0551 - acc: 0.9800 - val_loss: 0.0518 - val_acc: 0.9600\n",
      "Epoch 427/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 0.0550 - acc: 0.9700 - val_loss: 0.0515 - val_acc: 0.9600\n",
      "Epoch 428/1000\n",
      "100/100 [==============================] - 0s 72us/step - loss: 0.0547 - acc: 0.9800 - val_loss: 0.0518 - val_acc: 0.9600\n",
      "Epoch 429/1000\n",
      "100/100 [==============================] - 0s 63us/step - loss: 0.0543 - acc: 0.9800 - val_loss: 0.0528 - val_acc: 0.9600\n",
      "Epoch 430/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0544 - acc: 0.9800 - val_loss: 0.0540 - val_acc: 0.9600\n",
      "Epoch 431/1000\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.0541 - acc: 0.9800 - val_loss: 0.0544 - val_acc: 0.9600\n",
      "Epoch 432/1000\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.0543 - acc: 0.9700 - val_loss: 0.0545 - val_acc: 0.9600\n",
      "Epoch 433/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0540 - acc: 0.9700 - val_loss: 0.0536 - val_acc: 0.9600\n",
      "Epoch 434/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0536 - acc: 0.9800 - val_loss: 0.0524 - val_acc: 0.9600\n",
      "Epoch 435/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.0536 - acc: 0.9800 - val_loss: 0.0506 - val_acc: 0.9600\n",
      "Epoch 436/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0530 - acc: 0.9800 - val_loss: 0.0498 - val_acc: 0.9600\n",
      "Epoch 437/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.0530 - acc: 0.9700 - val_loss: 0.0494 - val_acc: 0.9800\n",
      "Epoch 438/1000\n",
      "100/100 [==============================] - 0s 138us/step - loss: 0.0529 - acc: 0.9700 - val_loss: 0.0492 - val_acc: 0.9800\n",
      "Epoch 439/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.0527 - acc: 0.9700 - val_loss: 0.0490 - val_acc: 0.9800\n",
      "Epoch 440/1000\n",
      "100/100 [==============================] - 0s 48us/step - loss: 0.0525 - acc: 0.9700 - val_loss: 0.0491 - val_acc: 0.9800\n",
      "Epoch 441/1000\n",
      "100/100 [==============================] - 0s 74us/step - loss: 0.0522 - acc: 0.9800 - val_loss: 0.0496 - val_acc: 0.9600\n",
      "Epoch 442/1000\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.0518 - acc: 0.9800 - val_loss: 0.0508 - val_acc: 0.9600\n",
      "Epoch 443/1000\n",
      "100/100 [==============================] - 0s 86us/step - loss: 0.0514 - acc: 0.9800 - val_loss: 0.0522 - val_acc: 0.9600\n",
      "Epoch 444/1000\n",
      "100/100 [==============================] - 0s 81us/step - loss: 0.0517 - acc: 0.9700 - val_loss: 0.0537 - val_acc: 0.9800\n",
      "Epoch 445/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 0.0521 - acc: 0.9800 - val_loss: 0.0544 - val_acc: 0.9600\n",
      "Epoch 446/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.0522 - acc: 0.9800 - val_loss: 0.0538 - val_acc: 0.9600\n",
      "Epoch 447/1000\n",
      "100/100 [==============================] - 0s 76us/step - loss: 0.0517 - acc: 0.9800 - val_loss: 0.0523 - val_acc: 0.9600\n",
      "Epoch 448/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0512 - acc: 0.9700 - val_loss: 0.0505 - val_acc: 0.9600\n",
      "Epoch 449/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.0506 - acc: 0.9800 - val_loss: 0.0491 - val_acc: 0.9600\n",
      "Epoch 450/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0504 - acc: 0.9800 - val_loss: 0.0480 - val_acc: 0.9600\n",
      "Epoch 451/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.0503 - acc: 0.9800 - val_loss: 0.0473 - val_acc: 0.9800\n",
      "Epoch 452/1000\n",
      "100/100 [==============================] - 0s 68us/step - loss: 0.0503 - acc: 0.9700 - val_loss: 0.0469 - val_acc: 0.9800\n",
      "Epoch 453/1000\n",
      "100/100 [==============================] - 0s 72us/step - loss: 0.0503 - acc: 0.9700 - val_loss: 0.0466 - val_acc: 0.9800\n",
      "Epoch 454/1000\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.0502 - acc: 0.9700 - val_loss: 0.0467 - val_acc: 0.9800\n",
      "Epoch 455/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.0500 - acc: 0.9700 - val_loss: 0.0471 - val_acc: 0.9600\n",
      "Epoch 456/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.0495 - acc: 0.9800 - val_loss: 0.0473 - val_acc: 0.9600\n",
      "Epoch 457/1000\n",
      "100/100 [==============================] - 0s 81us/step - loss: 0.0493 - acc: 0.9800 - val_loss: 0.0477 - val_acc: 0.9600\n",
      "Epoch 458/1000\n",
      "100/100 [==============================] - 0s 111us/step - loss: 0.0492 - acc: 0.9800 - val_loss: 0.0482 - val_acc: 0.9600\n",
      "Epoch 459/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0490 - acc: 0.9800 - val_loss: 0.0481 - val_acc: 0.9600\n",
      "Epoch 460/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.0489 - acc: 0.9800 - val_loss: 0.0478 - val_acc: 0.9600\n",
      "Epoch 461/1000\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.0486 - acc: 0.9800 - val_loss: 0.0479 - val_acc: 0.9600\n",
      "Epoch 462/1000\n",
      "100/100 [==============================] - 0s 69us/step - loss: 0.0485 - acc: 0.9800 - val_loss: 0.0479 - val_acc: 0.9600\n",
      "Epoch 463/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.0483 - acc: 0.9800 - val_loss: 0.0474 - val_acc: 0.9600\n",
      "Epoch 464/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.0482 - acc: 0.9800 - val_loss: 0.0469 - val_acc: 0.9600\n",
      "Epoch 465/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.0480 - acc: 0.9800 - val_loss: 0.0467 - val_acc: 0.9600\n",
      "Epoch 466/1000\n",
      "100/100 [==============================] - 0s 109us/step - loss: 0.0478 - acc: 0.9800 - val_loss: 0.0464 - val_acc: 0.9600\n",
      "Epoch 467/1000\n",
      "100/100 [==============================] - 0s 112us/step - loss: 0.0477 - acc: 0.9800 - val_loss: 0.0460 - val_acc: 0.9600\n",
      "Epoch 468/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.0476 - acc: 0.9800 - val_loss: 0.0456 - val_acc: 0.9600\n",
      "Epoch 469/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.0475 - acc: 0.9800 - val_loss: 0.0456 - val_acc: 0.9600\n",
      "Epoch 470/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.0473 - acc: 0.9800 - val_loss: 0.0454 - val_acc: 0.9600\n",
      "Epoch 471/1000\n",
      "100/100 [==============================] - 0s 85us/step - loss: 0.0471 - acc: 0.9800 - val_loss: 0.0456 - val_acc: 0.9600\n",
      "Epoch 472/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.0470 - acc: 0.9800 - val_loss: 0.0459 - val_acc: 0.9600\n",
      "Epoch 473/1000\n",
      "100/100 [==============================] - 0s 114us/step - loss: 0.0468 - acc: 0.9800 - val_loss: 0.0459 - val_acc: 0.9600\n",
      "Epoch 474/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0466 - acc: 0.9800 - val_loss: 0.0458 - val_acc: 0.9600\n",
      "Epoch 475/1000\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.0465 - acc: 0.9800 - val_loss: 0.0457 - val_acc: 0.9600\n",
      "Epoch 476/1000\n",
      "100/100 [==============================] - 0s 82us/step - loss: 0.0463 - acc: 0.9800 - val_loss: 0.0456 - val_acc: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 477/1000\n",
      "100/100 [==============================] - 0s 66us/step - loss: 0.0462 - acc: 0.9800 - val_loss: 0.0457 - val_acc: 0.9600\n",
      "Epoch 478/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.0460 - acc: 0.9800 - val_loss: 0.0461 - val_acc: 0.9600\n",
      "Epoch 479/1000\n",
      "100/100 [==============================] - 0s 45us/step - loss: 0.0459 - acc: 0.9800 - val_loss: 0.0467 - val_acc: 0.9600\n",
      "Epoch 480/1000\n",
      "100/100 [==============================] - 0s 85us/step - loss: 0.0461 - acc: 0.9800 - val_loss: 0.0468 - val_acc: 0.9600\n",
      "Epoch 481/1000\n",
      "100/100 [==============================] - 0s 123us/step - loss: 0.0458 - acc: 0.9800 - val_loss: 0.0459 - val_acc: 0.9600\n",
      "Epoch 482/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.0455 - acc: 0.9800 - val_loss: 0.0451 - val_acc: 0.9600\n",
      "Epoch 483/1000\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.0454 - acc: 0.9800 - val_loss: 0.0442 - val_acc: 0.9600\n",
      "Epoch 484/1000\n",
      "100/100 [==============================] - 0s 111us/step - loss: 0.0454 - acc: 0.9800 - val_loss: 0.0437 - val_acc: 0.9600\n",
      "Epoch 485/1000\n",
      "100/100 [==============================] - 0s 49us/step - loss: 0.0453 - acc: 0.9800 - val_loss: 0.0436 - val_acc: 0.9600\n",
      "Epoch 486/1000\n",
      "100/100 [==============================] - 0s 94us/step - loss: 0.0451 - acc: 0.9800 - val_loss: 0.0434 - val_acc: 0.9600\n",
      "Epoch 487/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.0450 - acc: 0.9800 - val_loss: 0.0435 - val_acc: 0.9600\n",
      "Epoch 488/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.0449 - acc: 0.9800 - val_loss: 0.0438 - val_acc: 0.9600\n",
      "Epoch 489/1000\n",
      "100/100 [==============================] - 0s 69us/step - loss: 0.0446 - acc: 0.9800 - val_loss: 0.0440 - val_acc: 0.9600\n",
      "Epoch 490/1000\n",
      "100/100 [==============================] - 0s 103us/step - loss: 0.0445 - acc: 0.9800 - val_loss: 0.0445 - val_acc: 0.9600\n",
      "Epoch 491/1000\n",
      "100/100 [==============================] - 0s 48us/step - loss: 0.0443 - acc: 0.9800 - val_loss: 0.0448 - val_acc: 0.9600\n",
      "Epoch 492/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.0442 - acc: 0.9800 - val_loss: 0.0451 - val_acc: 0.9600\n",
      "Epoch 493/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 0.0442 - acc: 0.9800 - val_loss: 0.0452 - val_acc: 0.9600\n",
      "Epoch 494/1000\n",
      "100/100 [==============================] - 0s 89us/step - loss: 0.0441 - acc: 0.9800 - val_loss: 0.0456 - val_acc: 0.9600\n",
      "Epoch 495/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 0.0445 - acc: 0.9700 - val_loss: 0.0459 - val_acc: 0.9600\n",
      "Epoch 496/1000\n",
      "100/100 [==============================] - 0s 48us/step - loss: 0.0444 - acc: 0.9800 - val_loss: 0.0449 - val_acc: 0.9600\n",
      "Epoch 497/1000\n",
      "100/100 [==============================] - 0s 102us/step - loss: 0.0437 - acc: 0.9800 - val_loss: 0.0445 - val_acc: 0.9600\n",
      "Epoch 498/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.0435 - acc: 0.9800 - val_loss: 0.0437 - val_acc: 0.9600\n",
      "Epoch 499/1000\n",
      "100/100 [==============================] - 0s 105us/step - loss: 0.0433 - acc: 0.9800 - val_loss: 0.0427 - val_acc: 0.9600\n",
      "Epoch 500/1000\n",
      "100/100 [==============================] - 0s 92us/step - loss: 0.0433 - acc: 0.9800 - val_loss: 0.0419 - val_acc: 0.9600\n",
      "Epoch 501/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.0433 - acc: 0.9800 - val_loss: 0.0415 - val_acc: 0.9600\n",
      "Epoch 502/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.0432 - acc: 0.9800 - val_loss: 0.0417 - val_acc: 0.9600\n",
      "Epoch 503/1000\n",
      "100/100 [==============================] - 0s 106us/step - loss: 0.0431 - acc: 0.9800 - val_loss: 0.0421 - val_acc: 0.9600\n",
      "Epoch 504/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.0430 - acc: 0.9800 - val_loss: 0.0421 - val_acc: 0.9600\n",
      "Epoch 505/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.0427 - acc: 0.9800 - val_loss: 0.0416 - val_acc: 0.9600\n",
      "Epoch 506/1000\n",
      "100/100 [==============================] - 0s 136us/step - loss: 0.0426 - acc: 0.9800 - val_loss: 0.0412 - val_acc: 0.9600\n",
      "Epoch 507/1000\n",
      "100/100 [==============================] - 0s 73us/step - loss: 0.0426 - acc: 0.9800 - val_loss: 0.0410 - val_acc: 0.9600\n",
      "Epoch 508/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0426 - acc: 0.9800 - val_loss: 0.0412 - val_acc: 0.9600\n",
      "Epoch 509/1000\n",
      "100/100 [==============================] - 0s 75us/step - loss: 0.0423 - acc: 0.9800 - val_loss: 0.0412 - val_acc: 0.9600\n",
      "Epoch 510/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0421 - acc: 0.9800 - val_loss: 0.0416 - val_acc: 0.9600\n",
      "Epoch 511/1000\n",
      "100/100 [==============================] - 0s 109us/step - loss: 0.0423 - acc: 0.9800 - val_loss: 0.0419 - val_acc: 0.9600\n",
      "Epoch 512/1000\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.0419 - acc: 0.9800 - val_loss: 0.0415 - val_acc: 0.9600\n",
      "Epoch 513/1000\n",
      "100/100 [==============================] - 0s 85us/step - loss: 0.0418 - acc: 0.9800 - val_loss: 0.0411 - val_acc: 0.9600\n",
      "Epoch 514/1000\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.0417 - acc: 0.9800 - val_loss: 0.0409 - val_acc: 0.9600\n",
      "Epoch 515/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0416 - acc: 0.9800 - val_loss: 0.0405 - val_acc: 0.9600\n",
      "Epoch 516/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.0416 - acc: 0.9800 - val_loss: 0.0404 - val_acc: 0.9600\n",
      "Epoch 517/1000\n",
      "100/100 [==============================] - 0s 95us/step - loss: 0.0414 - acc: 0.9800 - val_loss: 0.0406 - val_acc: 0.9600\n",
      "Epoch 518/1000\n",
      "100/100 [==============================] - 0s 75us/step - loss: 0.0412 - acc: 0.9800 - val_loss: 0.0411 - val_acc: 0.9600\n",
      "Epoch 519/1000\n",
      "100/100 [==============================] - 0s 86us/step - loss: 0.0411 - acc: 0.9800 - val_loss: 0.0419 - val_acc: 0.9600\n",
      "Epoch 520/1000\n",
      "100/100 [==============================] - 0s 87us/step - loss: 0.0410 - acc: 0.9800 - val_loss: 0.0426 - val_acc: 0.9600\n",
      "Epoch 521/1000\n",
      "100/100 [==============================] - 0s 63us/step - loss: 0.0410 - acc: 0.9800 - val_loss: 0.0431 - val_acc: 0.9600\n",
      "Epoch 522/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.0411 - acc: 0.9800 - val_loss: 0.0438 - val_acc: 0.9800\n",
      "Epoch 523/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0412 - acc: 0.9800 - val_loss: 0.0434 - val_acc: 0.9600\n",
      "Epoch 524/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0413 - acc: 0.9800 - val_loss: 0.0424 - val_acc: 0.9600\n",
      "Epoch 525/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0408 - acc: 0.9800 - val_loss: 0.0422 - val_acc: 0.9600\n",
      "Epoch 526/1000\n",
      "100/100 [==============================] - 0s 86us/step - loss: 0.0405 - acc: 0.9800 - val_loss: 0.0425 - val_acc: 0.9600\n",
      "Epoch 527/1000\n",
      "100/100 [==============================] - 0s 85us/step - loss: 0.0405 - acc: 0.9800 - val_loss: 0.0425 - val_acc: 0.9600\n",
      "Epoch 528/1000\n",
      "100/100 [==============================] - 0s 141us/step - loss: 0.0404 - acc: 0.9800 - val_loss: 0.0420 - val_acc: 0.9600\n",
      "Epoch 529/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0402 - acc: 0.9800 - val_loss: 0.0411 - val_acc: 0.9600\n",
      "Epoch 530/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.0399 - acc: 0.9800 - val_loss: 0.0400 - val_acc: 0.9600\n",
      "Epoch 531/1000\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.0400 - acc: 0.9800 - val_loss: 0.0389 - val_acc: 0.9600\n",
      "Epoch 532/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.0401 - acc: 0.9800 - val_loss: 0.0383 - val_acc: 0.9800\n",
      "Epoch 533/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.0400 - acc: 0.9800 - val_loss: 0.0382 - val_acc: 0.9800\n",
      "Epoch 534/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0399 - acc: 0.9800 - val_loss: 0.0383 - val_acc: 0.9800\n",
      "Epoch 535/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.0398 - acc: 0.9800 - val_loss: 0.0386 - val_acc: 0.9600\n",
      "Epoch 536/1000\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.0394 - acc: 0.9800 - val_loss: 0.0396 - val_acc: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 537/1000\n",
      "100/100 [==============================] - 0s 74us/step - loss: 0.0394 - acc: 0.9800 - val_loss: 0.0410 - val_acc: 0.9600\n",
      "Epoch 538/1000\n",
      "100/100 [==============================] - 0s 74us/step - loss: 0.0393 - acc: 0.9800 - val_loss: 0.0420 - val_acc: 0.9600\n",
      "Epoch 539/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0396 - acc: 0.9800 - val_loss: 0.0426 - val_acc: 0.9800\n",
      "Epoch 540/1000\n",
      "100/100 [==============================] - 0s 112us/step - loss: 0.0395 - acc: 0.9800 - val_loss: 0.0422 - val_acc: 0.9800\n",
      "Epoch 541/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.0392 - acc: 0.9800 - val_loss: 0.0409 - val_acc: 0.9600\n",
      "Epoch 542/1000\n",
      "100/100 [==============================] - 0s 68us/step - loss: 0.0389 - acc: 0.9800 - val_loss: 0.0396 - val_acc: 0.9600\n",
      "Epoch 543/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.0389 - acc: 0.9800 - val_loss: 0.0384 - val_acc: 0.9600\n",
      "Epoch 544/1000\n",
      "100/100 [==============================] - 0s 79us/step - loss: 0.0390 - acc: 0.9800 - val_loss: 0.0377 - val_acc: 0.9600\n",
      "Epoch 545/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0325 - acc: 0.985 - 0s 62us/step - loss: 0.0390 - acc: 0.9800 - val_loss: 0.0376 - val_acc: 0.9800\n",
      "Epoch 546/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.0388 - acc: 0.9800 - val_loss: 0.0372 - val_acc: 0.9800\n",
      "Epoch 547/1000\n",
      "100/100 [==============================] - 0s 75us/step - loss: 0.0388 - acc: 0.9800 - val_loss: 0.0367 - val_acc: 0.9800\n",
      "Epoch 548/1000\n",
      "100/100 [==============================] - 0s 83us/step - loss: 0.0390 - acc: 0.9700 - val_loss: 0.0363 - val_acc: 0.9800\n",
      "Epoch 549/1000\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.0390 - acc: 0.9700 - val_loss: 0.0364 - val_acc: 0.9800\n",
      "Epoch 550/1000\n",
      "100/100 [==============================] - 0s 63us/step - loss: 0.0388 - acc: 0.9800 - val_loss: 0.0369 - val_acc: 0.9800\n",
      "Epoch 551/1000\n",
      "100/100 [==============================] - 0s 44us/step - loss: 0.0385 - acc: 0.9800 - val_loss: 0.0376 - val_acc: 0.9800\n",
      "Epoch 552/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.0382 - acc: 0.9800 - val_loss: 0.0384 - val_acc: 0.9600\n",
      "Epoch 553/1000\n",
      "100/100 [==============================] - 0s 93us/step - loss: 0.0379 - acc: 0.9800 - val_loss: 0.0393 - val_acc: 0.9600\n",
      "Epoch 554/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.0379 - acc: 0.9800 - val_loss: 0.0405 - val_acc: 0.9600\n",
      "Epoch 555/1000\n",
      "100/100 [==============================] - 0s 77us/step - loss: 0.0382 - acc: 0.9800 - val_loss: 0.0412 - val_acc: 0.9600\n",
      "Epoch 556/1000\n",
      "100/100 [==============================] - 0s 92us/step - loss: 0.0379 - acc: 0.9800 - val_loss: 0.0407 - val_acc: 0.9600\n",
      "Epoch 557/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.0379 - acc: 0.9800 - val_loss: 0.0402 - val_acc: 0.9600\n",
      "Epoch 558/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 0.0376 - acc: 0.9800 - val_loss: 0.0402 - val_acc: 0.9600\n",
      "Epoch 559/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0375 - acc: 0.9800 - val_loss: 0.0400 - val_acc: 0.9600\n",
      "Epoch 560/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0375 - acc: 0.9800 - val_loss: 0.0396 - val_acc: 0.9600\n",
      "Epoch 561/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.0373 - acc: 0.9800 - val_loss: 0.0394 - val_acc: 0.9600\n",
      "Epoch 562/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0373 - acc: 0.9800 - val_loss: 0.0393 - val_acc: 0.9600\n",
      "Epoch 563/1000\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.0372 - acc: 0.9800 - val_loss: 0.0389 - val_acc: 0.9600\n",
      "Epoch 564/1000\n",
      "100/100 [==============================] - 0s 111us/step - loss: 0.0371 - acc: 0.9800 - val_loss: 0.0386 - val_acc: 0.9600\n",
      "Epoch 565/1000\n",
      "100/100 [==============================] - 0s 69us/step - loss: 0.0369 - acc: 0.9800 - val_loss: 0.0379 - val_acc: 0.9600\n",
      "Epoch 566/1000\n",
      "100/100 [==============================] - 0s 63us/step - loss: 0.0370 - acc: 0.9800 - val_loss: 0.0372 - val_acc: 0.9600\n",
      "Epoch 567/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.0369 - acc: 0.9800 - val_loss: 0.0369 - val_acc: 0.9600\n",
      "Epoch 568/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.0368 - acc: 0.9800 - val_loss: 0.0365 - val_acc: 0.9600\n",
      "Epoch 569/1000\n",
      "100/100 [==============================] - 0s 146us/step - loss: 0.0368 - acc: 0.9800 - val_loss: 0.0364 - val_acc: 0.9600\n",
      "Epoch 570/1000\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.0367 - acc: 0.9800 - val_loss: 0.0365 - val_acc: 0.9600\n",
      "Epoch 571/1000\n",
      "100/100 [==============================] - 0s 73us/step - loss: 0.0366 - acc: 0.9800 - val_loss: 0.0371 - val_acc: 0.9600\n",
      "Epoch 572/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.0365 - acc: 0.9800 - val_loss: 0.0381 - val_acc: 0.9600\n",
      "Epoch 573/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0373 - acc: 0.971 - 0s 73us/step - loss: 0.0365 - acc: 0.9800 - val_loss: 0.0387 - val_acc: 0.9600\n",
      "Epoch 574/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0363 - acc: 0.9800 - val_loss: 0.0387 - val_acc: 0.9600\n",
      "Epoch 575/1000\n",
      "100/100 [==============================] - 0s 66us/step - loss: 0.0363 - acc: 0.9800 - val_loss: 0.0384 - val_acc: 0.9600\n",
      "Epoch 576/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.0361 - acc: 0.9800 - val_loss: 0.0384 - val_acc: 0.9600\n",
      "Epoch 577/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.0361 - acc: 0.9800 - val_loss: 0.0383 - val_acc: 0.9600\n",
      "Epoch 578/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0360 - acc: 0.9800 - val_loss: 0.0383 - val_acc: 0.9600\n",
      "Epoch 579/1000\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.0362 - acc: 0.9800 - val_loss: 0.0381 - val_acc: 0.9600\n",
      "Epoch 580/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0359 - acc: 0.9800 - val_loss: 0.0370 - val_acc: 0.9600\n",
      "Epoch 581/1000\n",
      "100/100 [==============================] - 0s 81us/step - loss: 0.0358 - acc: 0.9800 - val_loss: 0.0362 - val_acc: 0.9600\n",
      "Epoch 582/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0358 - acc: 0.9800 - val_loss: 0.0359 - val_acc: 0.9600\n",
      "Epoch 583/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.0358 - acc: 0.9800 - val_loss: 0.0356 - val_acc: 0.9600\n",
      "Epoch 584/1000\n",
      "100/100 [==============================] - 0s 68us/step - loss: 0.0358 - acc: 0.9800 - val_loss: 0.0354 - val_acc: 0.9800\n",
      "Epoch 585/1000\n",
      "100/100 [==============================] - 0s 114us/step - loss: 0.0357 - acc: 0.9800 - val_loss: 0.0356 - val_acc: 0.9600\n",
      "Epoch 586/1000\n",
      "100/100 [==============================] - 0s 107us/step - loss: 0.0355 - acc: 0.9800 - val_loss: 0.0360 - val_acc: 0.9600\n",
      "Epoch 587/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.0355 - acc: 0.9800 - val_loss: 0.0365 - val_acc: 0.9600\n",
      "Epoch 588/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0354 - acc: 0.9800 - val_loss: 0.0367 - val_acc: 0.9600\n",
      "Epoch 589/1000\n",
      "100/100 [==============================] - 0s 73us/step - loss: 0.0352 - acc: 0.9800 - val_loss: 0.0365 - val_acc: 0.9600\n",
      "Epoch 590/1000\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.0352 - acc: 0.9800 - val_loss: 0.0364 - val_acc: 0.9600\n",
      "Epoch 591/1000\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.0351 - acc: 0.9800 - val_loss: 0.0363 - val_acc: 0.9600\n",
      "Epoch 592/1000\n",
      "100/100 [==============================] - 0s 95us/step - loss: 0.0350 - acc: 0.9800 - val_loss: 0.0359 - val_acc: 0.9600\n",
      "Epoch 593/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.0350 - acc: 0.9800 - val_loss: 0.0354 - val_acc: 0.9600\n",
      "Epoch 594/1000\n",
      "100/100 [==============================] - 0s 98us/step - loss: 0.0349 - acc: 0.9800 - val_loss: 0.0353 - val_acc: 0.9600\n",
      "Epoch 595/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0349 - acc: 0.9800 - val_loss: 0.0353 - val_acc: 0.9600\n",
      "Epoch 596/1000\n",
      "100/100 [==============================] - 0s 114us/step - loss: 0.0348 - acc: 0.9800 - val_loss: 0.0356 - val_acc: 0.9600\n",
      "Epoch 597/1000\n",
      "100/100 [==============================] - 0s 94us/step - loss: 0.0349 - acc: 0.9800 - val_loss: 0.0357 - val_acc: 0.9600\n",
      "Epoch 598/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.0347 - acc: 0.9800 - val_loss: 0.0354 - val_acc: 0.9600\n",
      "Epoch 599/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.0346 - acc: 0.9800 - val_loss: 0.0353 - val_acc: 0.9600\n",
      "Epoch 600/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.0345 - acc: 0.9800 - val_loss: 0.0351 - val_acc: 0.9600\n",
      "Epoch 601/1000\n",
      "100/100 [==============================] - 0s 77us/step - loss: 0.0345 - acc: 0.9800 - val_loss: 0.0352 - val_acc: 0.9600\n",
      "Epoch 602/1000\n",
      "100/100 [==============================] - 0s 114us/step - loss: 0.0344 - acc: 0.9800 - val_loss: 0.0353 - val_acc: 0.9600\n",
      "Epoch 603/1000\n",
      "100/100 [==============================] - 0s 74us/step - loss: 0.0345 - acc: 0.9800 - val_loss: 0.0355 - val_acc: 0.9600\n",
      "Epoch 604/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.0343 - acc: 0.9800 - val_loss: 0.0351 - val_acc: 0.9600\n",
      "Epoch 605/1000\n",
      "100/100 [==============================] - 0s 66us/step - loss: 0.0342 - acc: 0.9800 - val_loss: 0.0350 - val_acc: 0.9600\n",
      "Epoch 606/1000\n",
      "100/100 [==============================] - 0s 68us/step - loss: 0.0341 - acc: 0.9800 - val_loss: 0.0352 - val_acc: 0.9600\n",
      "Epoch 607/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.0341 - acc: 0.9800 - val_loss: 0.0355 - val_acc: 0.9600\n",
      "Epoch 608/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0366 - acc: 0.971 - 0s 80us/step - loss: 0.0340 - acc: 0.9800 - val_loss: 0.0356 - val_acc: 0.9600\n",
      "Epoch 609/1000\n",
      "100/100 [==============================] - 0s 74us/step - loss: 0.0340 - acc: 0.9800 - val_loss: 0.0356 - val_acc: 0.9600\n",
      "Epoch 610/1000\n",
      "100/100 [==============================] - 0s 73us/step - loss: 0.0339 - acc: 0.9800 - val_loss: 0.0360 - val_acc: 0.9600\n",
      "Epoch 611/1000\n",
      "100/100 [==============================] - 0s 63us/step - loss: 0.0338 - acc: 0.9800 - val_loss: 0.0361 - val_acc: 0.9600\n",
      "Epoch 612/1000\n",
      "100/100 [==============================] - 0s 49us/step - loss: 0.0338 - acc: 0.9800 - val_loss: 0.0362 - val_acc: 0.9600\n",
      "Epoch 613/1000\n",
      "100/100 [==============================] - 0s 74us/step - loss: 0.0337 - acc: 0.9800 - val_loss: 0.0365 - val_acc: 0.9600\n",
      "Epoch 614/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0336 - acc: 0.9800 - val_loss: 0.0367 - val_acc: 0.9600\n",
      "Epoch 615/1000\n",
      "100/100 [==============================] - 0s 75us/step - loss: 0.0337 - acc: 0.9800 - val_loss: 0.0370 - val_acc: 0.9600\n",
      "Epoch 616/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0336 - acc: 0.9800 - val_loss: 0.0375 - val_acc: 0.9600\n",
      "Epoch 617/1000\n",
      "100/100 [==============================] - 0s 95us/step - loss: 0.0336 - acc: 0.9800 - val_loss: 0.0378 - val_acc: 0.9800\n",
      "Epoch 618/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.0336 - acc: 0.9800 - val_loss: 0.0377 - val_acc: 0.9600\n",
      "Epoch 619/1000\n",
      "100/100 [==============================] - 0s 83us/step - loss: 0.0336 - acc: 0.9800 - val_loss: 0.0373 - val_acc: 0.9600\n",
      "Epoch 620/1000\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.0334 - acc: 0.9800 - val_loss: 0.0363 - val_acc: 0.9600\n",
      "Epoch 621/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.0332 - acc: 0.9800 - val_loss: 0.0352 - val_acc: 0.9600\n",
      "Epoch 622/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.0331 - acc: 0.9800 - val_loss: 0.0342 - val_acc: 0.9600\n",
      "Epoch 623/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0333 - acc: 0.9800 - val_loss: 0.0335 - val_acc: 0.9600\n",
      "Epoch 624/1000\n",
      "100/100 [==============================] - 0s 117us/step - loss: 0.0332 - acc: 0.9800 - val_loss: 0.0333 - val_acc: 0.9800\n",
      "Epoch 625/1000\n",
      "100/100 [==============================] - 0s 49us/step - loss: 0.0333 - acc: 0.9800 - val_loss: 0.0332 - val_acc: 0.9800\n",
      "Epoch 626/1000\n",
      "100/100 [==============================] - 0s 94us/step - loss: 0.0331 - acc: 0.9800 - val_loss: 0.0327 - val_acc: 0.9800\n",
      "Epoch 627/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.0331 - acc: 0.9800 - val_loss: 0.0326 - val_acc: 0.9800\n",
      "Epoch 628/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.0331 - acc: 0.9800 - val_loss: 0.0327 - val_acc: 0.9800\n",
      "Epoch 629/1000\n",
      "100/100 [==============================] - 0s 146us/step - loss: 0.0330 - acc: 0.9800 - val_loss: 0.0329 - val_acc: 0.9600\n",
      "Epoch 630/1000\n",
      "100/100 [==============================] - 0s 82us/step - loss: 0.0329 - acc: 0.9800 - val_loss: 0.0333 - val_acc: 0.9600\n",
      "Epoch 631/1000\n",
      "100/100 [==============================] - 0s 96us/step - loss: 0.0327 - acc: 0.9800 - val_loss: 0.0336 - val_acc: 0.9600\n",
      "Epoch 632/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.0326 - acc: 0.9800 - val_loss: 0.0341 - val_acc: 0.9600\n",
      "Epoch 633/1000\n",
      "100/100 [==============================] - 0s 95us/step - loss: 0.0325 - acc: 0.9800 - val_loss: 0.0348 - val_acc: 0.9600\n",
      "Epoch 634/1000\n",
      "100/100 [==============================] - 0s 63us/step - loss: 0.0324 - acc: 0.9800 - val_loss: 0.0356 - val_acc: 0.9600\n",
      "Epoch 635/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0325 - acc: 0.9800 - val_loss: 0.0365 - val_acc: 0.9800\n",
      "Epoch 636/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.0328 - acc: 0.9800 - val_loss: 0.0375 - val_acc: 0.9800\n",
      "Epoch 637/1000\n",
      "100/100 [==============================] - 0s 93us/step - loss: 0.0328 - acc: 0.9900 - val_loss: 0.0374 - val_acc: 0.9800\n",
      "Epoch 638/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0328 - acc: 0.9800 - val_loss: 0.0369 - val_acc: 0.9800\n",
      "Epoch 639/1000\n",
      "100/100 [==============================] - 0s 74us/step - loss: 0.0326 - acc: 0.9800 - val_loss: 0.0365 - val_acc: 0.9800\n",
      "Epoch 640/1000\n",
      "100/100 [==============================] - 0s 77us/step - loss: 0.0325 - acc: 0.9800 - val_loss: 0.0360 - val_acc: 0.9800\n",
      "Epoch 641/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0323 - acc: 0.9800 - val_loss: 0.0353 - val_acc: 0.9600\n",
      "Epoch 642/1000\n",
      "100/100 [==============================] - 0s 97us/step - loss: 0.0321 - acc: 0.9800 - val_loss: 0.0343 - val_acc: 0.9600\n",
      "Epoch 643/1000\n",
      "100/100 [==============================] - 0s 92us/step - loss: 0.0321 - acc: 0.9800 - val_loss: 0.0333 - val_acc: 0.9600\n",
      "Epoch 644/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.0319 - acc: 0.9800 - val_loss: 0.0328 - val_acc: 0.9600\n",
      "Epoch 645/1000\n",
      "100/100 [==============================] - 0s 74us/step - loss: 0.0319 - acc: 0.9800 - val_loss: 0.0323 - val_acc: 0.9600\n",
      "Epoch 646/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0319 - acc: 0.9800 - val_loss: 0.0319 - val_acc: 0.9800\n",
      "Epoch 647/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0320 - acc: 0.9800 - val_loss: 0.0315 - val_acc: 0.9800\n",
      "Epoch 648/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.0320 - acc: 0.9800 - val_loss: 0.0312 - val_acc: 0.9800\n",
      "Epoch 649/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.0322 - acc: 0.9800 - val_loss: 0.0312 - val_acc: 0.9800\n",
      "Epoch 650/1000\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.0321 - acc: 0.9800 - val_loss: 0.0318 - val_acc: 0.9800\n",
      "Epoch 651/1000\n",
      "100/100 [==============================] - 0s 83us/step - loss: 0.0317 - acc: 0.9800 - val_loss: 0.0324 - val_acc: 0.9600\n",
      "Epoch 652/1000\n",
      "100/100 [==============================] - 0s 92us/step - loss: 0.0315 - acc: 0.9800 - val_loss: 0.0335 - val_acc: 0.9600\n",
      "Epoch 653/1000\n",
      "100/100 [==============================] - 0s 78us/step - loss: 0.0317 - acc: 0.9800 - val_loss: 0.0345 - val_acc: 0.9600\n",
      "Epoch 654/1000\n",
      "100/100 [==============================] - 0s 74us/step - loss: 0.0315 - acc: 0.9800 - val_loss: 0.0348 - val_acc: 0.9600\n",
      "Epoch 655/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 54us/step - loss: 0.0315 - acc: 0.9800 - val_loss: 0.0353 - val_acc: 0.9600\n",
      "Epoch 656/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0246 - acc: 0.985 - 0s 104us/step - loss: 0.0315 - acc: 0.9800 - val_loss: 0.0352 - val_acc: 0.9600\n",
      "Epoch 657/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.0314 - acc: 0.9800 - val_loss: 0.0348 - val_acc: 0.9600\n",
      "Epoch 658/1000\n",
      "100/100 [==============================] - 0s 46us/step - loss: 0.0313 - acc: 0.9800 - val_loss: 0.0344 - val_acc: 0.9600\n",
      "Epoch 659/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.0312 - acc: 0.9800 - val_loss: 0.0338 - val_acc: 0.9600\n",
      "Epoch 660/1000\n",
      "100/100 [==============================] - 0s 48us/step - loss: 0.0311 - acc: 0.9800 - val_loss: 0.0328 - val_acc: 0.9600\n",
      "Epoch 661/1000\n",
      "100/100 [==============================] - 0s 75us/step - loss: 0.0310 - acc: 0.9800 - val_loss: 0.0318 - val_acc: 0.9600\n",
      "Epoch 662/1000\n",
      "100/100 [==============================] - 0s 92us/step - loss: 0.0317 - acc: 0.9800 - val_loss: 0.0311 - val_acc: 0.9800\n",
      "Epoch 663/1000\n",
      "100/100 [==============================] - 0s 63us/step - loss: 0.0312 - acc: 0.9800 - val_loss: 0.0317 - val_acc: 0.9600\n",
      "Epoch 664/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 0.0312 - acc: 0.9800 - val_loss: 0.0324 - val_acc: 0.9600\n",
      "Epoch 665/1000\n",
      "100/100 [==============================] - 0s 74us/step - loss: 0.0309 - acc: 0.9800 - val_loss: 0.0330 - val_acc: 0.9600\n",
      "Epoch 666/1000\n",
      "100/100 [==============================] - 0s 45us/step - loss: 0.0309 - acc: 0.9800 - val_loss: 0.0336 - val_acc: 0.9600\n",
      "Epoch 667/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.0308 - acc: 0.9800 - val_loss: 0.0340 - val_acc: 0.9600\n",
      "Epoch 668/1000\n",
      "100/100 [==============================] - 0s 155us/step - loss: 0.0308 - acc: 0.9800 - val_loss: 0.0346 - val_acc: 0.9600\n",
      "Epoch 669/1000\n",
      "100/100 [==============================] - 0s 85us/step - loss: 0.0309 - acc: 0.9800 - val_loss: 0.0347 - val_acc: 0.9600\n",
      "Epoch 670/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.0308 - acc: 0.9800 - val_loss: 0.0343 - val_acc: 0.9600\n",
      "Epoch 671/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0285 - acc: 0.985 - 0s 55us/step - loss: 0.0307 - acc: 0.9800 - val_loss: 0.0339 - val_acc: 0.9600\n",
      "Epoch 672/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.0306 - acc: 0.9800 - val_loss: 0.0330 - val_acc: 0.9600\n",
      "Epoch 673/1000\n",
      "100/100 [==============================] - 0s 79us/step - loss: 0.0305 - acc: 0.9800 - val_loss: 0.0317 - val_acc: 0.9600\n",
      "Epoch 674/1000\n",
      "100/100 [==============================] - 0s 47us/step - loss: 0.0305 - acc: 0.9800 - val_loss: 0.0310 - val_acc: 0.9600\n",
      "Epoch 675/1000\n",
      "100/100 [==============================] - 0s 99us/step - loss: 0.0307 - acc: 0.9800 - val_loss: 0.0306 - val_acc: 0.9800\n",
      "Epoch 676/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0306 - acc: 0.9800 - val_loss: 0.0309 - val_acc: 0.9600\n",
      "Epoch 677/1000\n",
      "100/100 [==============================] - 0s 78us/step - loss: 0.0306 - acc: 0.9800 - val_loss: 0.0315 - val_acc: 0.9600\n",
      "Epoch 678/1000\n",
      "100/100 [==============================] - 0s 76us/step - loss: 0.0304 - acc: 0.9800 - val_loss: 0.0317 - val_acc: 0.9600\n",
      "Epoch 679/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.0303 - acc: 0.9800 - val_loss: 0.0319 - val_acc: 0.9600\n",
      "Epoch 680/1000\n",
      "100/100 [==============================] - 0s 76us/step - loss: 0.0303 - acc: 0.9800 - val_loss: 0.0318 - val_acc: 0.9600\n",
      "Epoch 681/1000\n",
      "100/100 [==============================] - 0s 72us/step - loss: 0.0302 - acc: 0.9800 - val_loss: 0.0321 - val_acc: 0.9600\n",
      "Epoch 682/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.0301 - acc: 0.9800 - val_loss: 0.0323 - val_acc: 0.9600\n",
      "Epoch 683/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0301 - acc: 0.9800 - val_loss: 0.0326 - val_acc: 0.9600\n",
      "Epoch 684/1000\n",
      "100/100 [==============================] - 0s 75us/step - loss: 0.0301 - acc: 0.9800 - val_loss: 0.0328 - val_acc: 0.9600\n",
      "Epoch 685/1000\n",
      "100/100 [==============================] - 0s 84us/step - loss: 0.0300 - acc: 0.9800 - val_loss: 0.0328 - val_acc: 0.9600\n",
      "Epoch 686/1000\n",
      "100/100 [==============================] - 0s 74us/step - loss: 0.0300 - acc: 0.9800 - val_loss: 0.0329 - val_acc: 0.9600\n",
      "Epoch 687/1000\n",
      "100/100 [==============================] - 0s 68us/step - loss: 0.0299 - acc: 0.9800 - val_loss: 0.0328 - val_acc: 0.9600\n",
      "Epoch 688/1000\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.0299 - acc: 0.9800 - val_loss: 0.0329 - val_acc: 0.9600\n",
      "Epoch 689/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0298 - acc: 0.9800 - val_loss: 0.0333 - val_acc: 0.9600\n",
      "Epoch 690/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.0300 - acc: 0.9800 - val_loss: 0.0336 - val_acc: 0.9600\n",
      "Epoch 691/1000\n",
      "100/100 [==============================] - 0s 127us/step - loss: 0.0298 - acc: 0.9800 - val_loss: 0.0329 - val_acc: 0.9600\n",
      "Epoch 692/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0297 - acc: 0.9800 - val_loss: 0.0320 - val_acc: 0.9600\n",
      "Epoch 693/1000\n",
      "100/100 [==============================] - 0s 160us/step - loss: 0.0296 - acc: 0.9800 - val_loss: 0.0313 - val_acc: 0.9600\n",
      "Epoch 694/1000\n",
      "100/100 [==============================] - 0s 72us/step - loss: 0.0296 - acc: 0.9800 - val_loss: 0.0306 - val_acc: 0.9600\n",
      "Epoch 695/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0297 - acc: 0.9800 - val_loss: 0.0299 - val_acc: 0.9800\n",
      "Epoch 696/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.0298 - acc: 0.9800 - val_loss: 0.0295 - val_acc: 0.9800\n",
      "Epoch 697/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.0300 - acc: 0.9800 - val_loss: 0.0291 - val_acc: 0.9800\n",
      "Epoch 698/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.0299 - acc: 0.9800 - val_loss: 0.0294 - val_acc: 0.9800\n",
      "Epoch 699/1000\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.0297 - acc: 0.9800 - val_loss: 0.0298 - val_acc: 0.9800\n",
      "Epoch 700/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0298 - acc: 0.9800 - val_loss: 0.0305 - val_acc: 0.9600\n",
      "Epoch 701/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.0294 - acc: 0.9800 - val_loss: 0.0308 - val_acc: 0.9600\n",
      "Epoch 702/1000\n",
      "100/100 [==============================] - 0s 66us/step - loss: 0.0293 - acc: 0.9800 - val_loss: 0.0313 - val_acc: 0.9600\n",
      "Epoch 703/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.0293 - acc: 0.9800 - val_loss: 0.0319 - val_acc: 0.9600\n",
      "Epoch 704/1000\n",
      "100/100 [==============================] - 0s 48us/step - loss: 0.0292 - acc: 0.9800 - val_loss: 0.0322 - val_acc: 0.9600\n",
      "Epoch 705/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.0292 - acc: 0.9800 - val_loss: 0.0325 - val_acc: 0.9600\n",
      "Epoch 706/1000\n",
      "100/100 [==============================] - 0s 112us/step - loss: 0.0295 - acc: 0.9800 - val_loss: 0.0330 - val_acc: 0.9600\n",
      "Epoch 707/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.0293 - acc: 0.9800 - val_loss: 0.0325 - val_acc: 0.9600\n",
      "Epoch 708/1000\n",
      "100/100 [==============================] - 0s 96us/step - loss: 0.0292 - acc: 0.9800 - val_loss: 0.0322 - val_acc: 0.9600\n",
      "Epoch 709/1000\n",
      "100/100 [==============================] - 0s 47us/step - loss: 0.0291 - acc: 0.9800 - val_loss: 0.0313 - val_acc: 0.9600\n",
      "Epoch 710/1000\n",
      "100/100 [==============================] - 0s 101us/step - loss: 0.0290 - acc: 0.9800 - val_loss: 0.0308 - val_acc: 0.9600\n",
      "Epoch 711/1000\n",
      "100/100 [==============================] - 0s 72us/step - loss: 0.0290 - acc: 0.9800 - val_loss: 0.0304 - val_acc: 0.9600\n",
      "Epoch 712/1000\n",
      "100/100 [==============================] - 0s 77us/step - loss: 0.0292 - acc: 0.9800 - val_loss: 0.0300 - val_acc: 0.9600\n",
      "Epoch 713/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.0290 - acc: 0.9800 - val_loss: 0.0303 - val_acc: 0.9600\n",
      "Epoch 714/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.0289 - acc: 0.9800 - val_loss: 0.0306 - val_acc: 0.9600\n",
      "Epoch 715/1000\n",
      "100/100 [==============================] - 0s 86us/step - loss: 0.0289 - acc: 0.9800 - val_loss: 0.0308 - val_acc: 0.9600\n",
      "Epoch 716/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.0288 - acc: 0.9800 - val_loss: 0.0307 - val_acc: 0.9600\n",
      "Epoch 717/1000\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.0287 - acc: 0.9800 - val_loss: 0.0307 - val_acc: 0.9600\n",
      "Epoch 718/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.0287 - acc: 0.9800 - val_loss: 0.0309 - val_acc: 0.9600\n",
      "Epoch 719/1000\n",
      "100/100 [==============================] - 0s 91us/step - loss: 0.0287 - acc: 0.9800 - val_loss: 0.0308 - val_acc: 0.9600\n",
      "Epoch 720/1000\n",
      "100/100 [==============================] - 0s 75us/step - loss: 0.0286 - acc: 0.9800 - val_loss: 0.0305 - val_acc: 0.9600\n",
      "Epoch 721/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.0287 - acc: 0.9800 - val_loss: 0.0303 - val_acc: 0.9600\n",
      "Epoch 722/1000\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.0285 - acc: 0.9800 - val_loss: 0.0295 - val_acc: 0.9600\n",
      "Epoch 723/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.0286 - acc: 0.9800 - val_loss: 0.0291 - val_acc: 0.9600\n",
      "Epoch 724/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.0287 - acc: 0.9800 - val_loss: 0.0289 - val_acc: 0.9800\n",
      "Epoch 725/1000\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.0286 - acc: 0.9800 - val_loss: 0.0293 - val_acc: 0.9600\n",
      "Epoch 726/1000\n",
      "100/100 [==============================] - 0s 49us/step - loss: 0.0285 - acc: 0.9800 - val_loss: 0.0297 - val_acc: 0.9600\n",
      "Epoch 727/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0275 - acc: 0.985 - 0s 119us/step - loss: 0.0284 - acc: 0.9800 - val_loss: 0.0303 - val_acc: 0.9600\n",
      "Epoch 728/1000\n",
      "100/100 [==============================] - 0s 106us/step - loss: 0.0282 - acc: 0.9800 - val_loss: 0.0315 - val_acc: 0.9600\n",
      "Epoch 729/1000\n",
      "100/100 [==============================] - 0s 84us/step - loss: 0.0282 - acc: 0.9800 - val_loss: 0.0329 - val_acc: 0.9800\n",
      "Epoch 730/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.0284 - acc: 0.9800 - val_loss: 0.0342 - val_acc: 0.9800\n",
      "Epoch 731/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.0287 - acc: 0.9900 - val_loss: 0.0350 - val_acc: 0.9800\n",
      "Epoch 732/1000\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.0289 - acc: 0.9900 - val_loss: 0.0347 - val_acc: 0.9800\n",
      "Epoch 733/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.0289 - acc: 0.9800 - val_loss: 0.0339 - val_acc: 0.9800\n",
      "Epoch 734/1000\n",
      "100/100 [==============================] - 0s 68us/step - loss: 0.0285 - acc: 0.9800 - val_loss: 0.0331 - val_acc: 0.9800\n",
      "Epoch 735/1000\n",
      "100/100 [==============================] - 0s 49us/step - loss: 0.0284 - acc: 0.9800 - val_loss: 0.0322 - val_acc: 0.9600\n",
      "Epoch 736/1000\n",
      "100/100 [==============================] - 0s 81us/step - loss: 0.0281 - acc: 0.9800 - val_loss: 0.0315 - val_acc: 0.9600\n",
      "Epoch 737/1000\n",
      "100/100 [==============================] - 0s 73us/step - loss: 0.0282 - acc: 0.9800 - val_loss: 0.0306 - val_acc: 0.9600\n",
      "Epoch 738/1000\n",
      "100/100 [==============================] - 0s 75us/step - loss: 0.0280 - acc: 0.9800 - val_loss: 0.0300 - val_acc: 0.9600\n",
      "Epoch 739/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.0279 - acc: 0.9800 - val_loss: 0.0290 - val_acc: 0.9600\n",
      "Epoch 740/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0280 - acc: 0.9800 - val_loss: 0.0282 - val_acc: 0.9800\n",
      "Epoch 741/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.0283 - acc: 0.9800 - val_loss: 0.0280 - val_acc: 0.9800\n",
      "Epoch 742/1000\n",
      "100/100 [==============================] - 0s 74us/step - loss: 0.0282 - acc: 0.9800 - val_loss: 0.0283 - val_acc: 0.9800\n",
      "Epoch 743/1000\n",
      "100/100 [==============================] - 0s 134us/step - loss: 0.0280 - acc: 0.9800 - val_loss: 0.0287 - val_acc: 0.9600\n",
      "Epoch 744/1000\n",
      "100/100 [==============================] - 0s 83us/step - loss: 0.0279 - acc: 0.9800 - val_loss: 0.0293 - val_acc: 0.9600\n",
      "Epoch 745/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.0280 - acc: 0.9800 - val_loss: 0.0297 - val_acc: 0.9600\n",
      "Epoch 746/1000\n",
      "100/100 [==============================] - 0s 73us/step - loss: 0.0278 - acc: 0.9800 - val_loss: 0.0295 - val_acc: 0.9600\n",
      "Epoch 747/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0297 - acc: 0.971 - 0s 59us/step - loss: 0.0277 - acc: 0.9800 - val_loss: 0.0300 - val_acc: 0.9600\n",
      "Epoch 748/1000\n",
      "100/100 [==============================] - 0s 69us/step - loss: 0.0277 - acc: 0.9800 - val_loss: 0.0303 - val_acc: 0.9600\n",
      "Epoch 749/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.0276 - acc: 0.9800 - val_loss: 0.0302 - val_acc: 0.9600\n",
      "Epoch 750/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0276 - acc: 0.9800 - val_loss: 0.0299 - val_acc: 0.9600\n",
      "Epoch 751/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.0275 - acc: 0.9800 - val_loss: 0.0296 - val_acc: 0.9600\n",
      "Epoch 752/1000\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.0275 - acc: 0.9800 - val_loss: 0.0293 - val_acc: 0.9600\n",
      "Epoch 753/1000\n",
      "100/100 [==============================] - 0s 66us/step - loss: 0.0275 - acc: 0.9800 - val_loss: 0.0292 - val_acc: 0.9600\n",
      "Epoch 754/1000\n",
      "100/100 [==============================] - 0s 88us/step - loss: 0.0276 - acc: 0.9800 - val_loss: 0.0291 - val_acc: 0.9600\n",
      "Epoch 755/1000\n",
      "100/100 [==============================] - 0s 87us/step - loss: 0.0274 - acc: 0.9800 - val_loss: 0.0297 - val_acc: 0.9600\n",
      "Epoch 756/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.0273 - acc: 0.9800 - val_loss: 0.0304 - val_acc: 0.9600\n",
      "Epoch 757/1000\n",
      "100/100 [==============================] - 0s 116us/step - loss: 0.0274 - acc: 0.9800 - val_loss: 0.0311 - val_acc: 0.9800\n",
      "Epoch 758/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0274 - acc: 0.9800 - val_loss: 0.0313 - val_acc: 0.9800\n",
      "Epoch 759/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0274 - acc: 0.9800 - val_loss: 0.0312 - val_acc: 0.9800\n",
      "Epoch 760/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.0275 - acc: 0.9800 - val_loss: 0.0306 - val_acc: 0.9600\n",
      "Epoch 761/1000\n",
      "100/100 [==============================] - 0s 66us/step - loss: 0.0273 - acc: 0.9800 - val_loss: 0.0303 - val_acc: 0.9600\n",
      "Epoch 762/1000\n",
      "100/100 [==============================] - 0s 48us/step - loss: 0.0272 - acc: 0.9800 - val_loss: 0.0295 - val_acc: 0.9600\n",
      "Epoch 763/1000\n",
      "100/100 [==============================] - 0s 76us/step - loss: 0.0271 - acc: 0.9800 - val_loss: 0.0290 - val_acc: 0.9600\n",
      "Epoch 764/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.0271 - acc: 0.9800 - val_loss: 0.0284 - val_acc: 0.9600\n",
      "Epoch 765/1000\n",
      "100/100 [==============================] - 0s 75us/step - loss: 0.0271 - acc: 0.9800 - val_loss: 0.0279 - val_acc: 0.9600\n",
      "Epoch 766/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.0272 - acc: 0.9800 - val_loss: 0.0274 - val_acc: 0.9800\n",
      "Epoch 767/1000\n",
      "100/100 [==============================] - 0s 81us/step - loss: 0.0273 - acc: 0.9800 - val_loss: 0.0271 - val_acc: 0.9800\n",
      "Epoch 768/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.0273 - acc: 0.9800 - val_loss: 0.0269 - val_acc: 0.9800\n",
      "Epoch 769/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.0273 - acc: 0.9800 - val_loss: 0.0270 - val_acc: 0.9800\n",
      "Epoch 770/1000\n",
      "100/100 [==============================] - 0s 75us/step - loss: 0.0273 - acc: 0.9800 - val_loss: 0.0273 - val_acc: 0.9600\n",
      "Epoch 771/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0271 - acc: 0.9800 - val_loss: 0.0276 - val_acc: 0.9600\n",
      "Epoch 772/1000\n",
      "100/100 [==============================] - 0s 81us/step - loss: 0.0270 - acc: 0.9800 - val_loss: 0.0280 - val_acc: 0.9600\n",
      "Epoch 773/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 68us/step - loss: 0.0269 - acc: 0.9800 - val_loss: 0.0287 - val_acc: 0.9600\n",
      "Epoch 774/1000\n",
      "100/100 [==============================] - 0s 63us/step - loss: 0.0269 - acc: 0.9800 - val_loss: 0.0293 - val_acc: 0.9600\n",
      "Epoch 775/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0269 - acc: 0.9800 - val_loss: 0.0295 - val_acc: 0.9600\n",
      "Epoch 776/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.0267 - acc: 0.9800 - val_loss: 0.0290 - val_acc: 0.9600\n",
      "Epoch 777/1000\n",
      "100/100 [==============================] - 0s 85us/step - loss: 0.0267 - acc: 0.9800 - val_loss: 0.0282 - val_acc: 0.9600\n",
      "Epoch 778/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0267 - acc: 0.9800 - val_loss: 0.0273 - val_acc: 0.9600\n",
      "Epoch 779/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 0.0268 - acc: 0.9800 - val_loss: 0.0268 - val_acc: 0.9800\n",
      "Epoch 780/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0269 - acc: 0.9800 - val_loss: 0.0267 - val_acc: 0.9800\n",
      "Epoch 781/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0269 - acc: 0.9800 - val_loss: 0.0267 - val_acc: 0.9800\n",
      "Epoch 782/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.0268 - acc: 0.9800 - val_loss: 0.0270 - val_acc: 0.9600\n",
      "Epoch 783/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.0269 - acc: 0.9800 - val_loss: 0.0273 - val_acc: 0.9600\n",
      "Epoch 784/1000\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.0266 - acc: 0.9800 - val_loss: 0.0274 - val_acc: 0.9600\n",
      "Epoch 785/1000\n",
      "100/100 [==============================] - 0s 49us/step - loss: 0.0268 - acc: 0.9800 - val_loss: 0.0276 - val_acc: 0.9600\n",
      "Epoch 786/1000\n",
      "100/100 [==============================] - 0s 69us/step - loss: 0.0266 - acc: 0.9800 - val_loss: 0.0286 - val_acc: 0.9600\n",
      "Epoch 787/1000\n",
      "100/100 [==============================] - 0s 48us/step - loss: 0.0264 - acc: 0.9800 - val_loss: 0.0292 - val_acc: 0.9600\n",
      "Epoch 788/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0265 - acc: 0.9800 - val_loss: 0.0296 - val_acc: 0.9800\n",
      "Epoch 789/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.0264 - acc: 0.9800 - val_loss: 0.0297 - val_acc: 0.9800\n",
      "Epoch 790/1000\n",
      "100/100 [==============================] - 0s 104us/step - loss: 0.0264 - acc: 0.9800 - val_loss: 0.0296 - val_acc: 0.9600\n",
      "Epoch 791/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.0263 - acc: 0.9800 - val_loss: 0.0294 - val_acc: 0.9600\n",
      "Epoch 792/1000\n",
      "100/100 [==============================] - 0s 95us/step - loss: 0.0263 - acc: 0.9800 - val_loss: 0.0288 - val_acc: 0.9600\n",
      "Epoch 793/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.0262 - acc: 0.9800 - val_loss: 0.0280 - val_acc: 0.9600\n",
      "Epoch 794/1000\n",
      "100/100 [==============================] - 0s 87us/step - loss: 0.0262 - acc: 0.9800 - val_loss: 0.0273 - val_acc: 0.9600\n",
      "Epoch 795/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.0262 - acc: 0.9800 - val_loss: 0.0267 - val_acc: 0.9800\n",
      "Epoch 796/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.0264 - acc: 0.9800 - val_loss: 0.0264 - val_acc: 0.9800\n",
      "Epoch 797/1000\n",
      "100/100 [==============================] - 0s 63us/step - loss: 0.0264 - acc: 0.9800 - val_loss: 0.0263 - val_acc: 0.9800\n",
      "Epoch 798/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.0264 - acc: 0.9800 - val_loss: 0.0264 - val_acc: 0.9800\n",
      "Epoch 799/1000\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.0263 - acc: 0.9800 - val_loss: 0.0270 - val_acc: 0.9600\n",
      "Epoch 800/1000\n",
      "100/100 [==============================] - 0s 75us/step - loss: 0.0264 - acc: 0.9800 - val_loss: 0.0279 - val_acc: 0.9600\n",
      "Epoch 801/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.0260 - acc: 0.9800 - val_loss: 0.0283 - val_acc: 0.9600\n",
      "Epoch 802/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0260 - acc: 0.9800 - val_loss: 0.0288 - val_acc: 0.9600\n",
      "Epoch 803/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.0259 - acc: 0.9800 - val_loss: 0.0295 - val_acc: 0.9800\n",
      "Epoch 804/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.0260 - acc: 0.9800 - val_loss: 0.0303 - val_acc: 0.9800\n",
      "Epoch 805/1000\n",
      "100/100 [==============================] - 0s 126us/step - loss: 0.0260 - acc: 0.9800 - val_loss: 0.0309 - val_acc: 0.9800\n",
      "Epoch 806/1000\n",
      "100/100 [==============================] - 0s 69us/step - loss: 0.0261 - acc: 0.9800 - val_loss: 0.0311 - val_acc: 0.9800\n",
      "Epoch 807/1000\n",
      "100/100 [==============================] - 0s 45us/step - loss: 0.0261 - acc: 0.9800 - val_loss: 0.0309 - val_acc: 0.9800\n",
      "Epoch 808/1000\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.0260 - acc: 0.9800 - val_loss: 0.0299 - val_acc: 0.9800\n",
      "Epoch 809/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0259 - acc: 0.9800 - val_loss: 0.0290 - val_acc: 0.9600\n",
      "Epoch 810/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.0258 - acc: 0.9800 - val_loss: 0.0283 - val_acc: 0.9600\n",
      "Epoch 811/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0257 - acc: 0.9800 - val_loss: 0.0278 - val_acc: 0.9600\n",
      "Epoch 812/1000\n",
      "100/100 [==============================] - 0s 86us/step - loss: 0.0257 - acc: 0.9800 - val_loss: 0.0274 - val_acc: 0.9600\n",
      "Epoch 813/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.0258 - acc: 0.9800 - val_loss: 0.0271 - val_acc: 0.9600\n",
      "Epoch 814/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0258 - acc: 0.9800 - val_loss: 0.0275 - val_acc: 0.9600\n",
      "Epoch 815/1000\n",
      "100/100 [==============================] - 0s 49us/step - loss: 0.0256 - acc: 0.9800 - val_loss: 0.0284 - val_acc: 0.9600\n",
      "Epoch 816/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.0255 - acc: 0.9800 - val_loss: 0.0297 - val_acc: 0.9800\n",
      "Epoch 817/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0258 - acc: 0.9800 - val_loss: 0.0311 - val_acc: 0.9800\n",
      "Epoch 818/1000\n",
      "100/100 [==============================] - 0s 88us/step - loss: 0.0262 - acc: 0.9800 - val_loss: 0.0315 - val_acc: 0.9800\n",
      "Epoch 819/1000\n",
      "100/100 [==============================] - 0s 83us/step - loss: 0.0259 - acc: 0.9800 - val_loss: 0.0304 - val_acc: 0.9800\n",
      "Epoch 820/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.0256 - acc: 0.9800 - val_loss: 0.0293 - val_acc: 0.9600\n",
      "Epoch 821/1000\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.0256 - acc: 0.9800 - val_loss: 0.0282 - val_acc: 0.9600\n",
      "Epoch 822/1000\n",
      "100/100 [==============================] - 0s 46us/step - loss: 0.0254 - acc: 0.9800 - val_loss: 0.0276 - val_acc: 0.9600\n",
      "Epoch 823/1000\n",
      "100/100 [==============================] - 0s 82us/step - loss: 0.0257 - acc: 0.9800 - val_loss: 0.0268 - val_acc: 0.9600\n",
      "Epoch 824/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0255 - acc: 0.9800 - val_loss: 0.0267 - val_acc: 0.9600\n",
      "Epoch 825/1000\n",
      "100/100 [==============================] - 0s 92us/step - loss: 0.0255 - acc: 0.9800 - val_loss: 0.0268 - val_acc: 0.9600\n",
      "Epoch 826/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.0254 - acc: 0.9800 - val_loss: 0.0274 - val_acc: 0.9600\n",
      "Epoch 827/1000\n",
      "100/100 [==============================] - 0s 45us/step - loss: 0.0253 - acc: 0.9800 - val_loss: 0.0283 - val_acc: 0.9600\n",
      "Epoch 828/1000\n",
      "100/100 [==============================] - 0s 68us/step - loss: 0.0254 - acc: 0.9800 - val_loss: 0.0289 - val_acc: 0.9800\n",
      "Epoch 829/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0255 - acc: 0.9800 - val_loss: 0.0289 - val_acc: 0.9800\n",
      "Epoch 830/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0253 - acc: 0.9800 - val_loss: 0.0281 - val_acc: 0.9600\n",
      "Epoch 831/1000\n",
      "100/100 [==============================] - 0s 46us/step - loss: 0.0252 - acc: 0.9800 - val_loss: 0.0269 - val_acc: 0.9600\n",
      "Epoch 832/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.0253 - acc: 0.9800 - val_loss: 0.0262 - val_acc: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 833/1000\n",
      "100/100 [==============================] - 0s 82us/step - loss: 0.0257 - acc: 0.9800 - val_loss: 0.0260 - val_acc: 0.9600\n",
      "Epoch 834/1000\n",
      "100/100 [==============================] - 0s 84us/step - loss: 0.0253 - acc: 0.9800 - val_loss: 0.0267 - val_acc: 0.9600\n",
      "Epoch 835/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 0.0253 - acc: 0.9800 - val_loss: 0.0273 - val_acc: 0.9600\n",
      "Epoch 836/1000\n",
      "100/100 [==============================] - 0s 72us/step - loss: 0.0252 - acc: 0.9800 - val_loss: 0.0274 - val_acc: 0.9600\n",
      "Epoch 837/1000\n",
      "100/100 [==============================] - 0s 41us/step - loss: 0.0251 - acc: 0.9800 - val_loss: 0.0273 - val_acc: 0.9600\n",
      "Epoch 838/1000\n",
      "100/100 [==============================] - 0s 47us/step - loss: 0.0251 - acc: 0.9800 - val_loss: 0.0275 - val_acc: 0.9600\n",
      "Epoch 839/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.0250 - acc: 0.9800 - val_loss: 0.0275 - val_acc: 0.9600\n",
      "Epoch 840/1000\n",
      "100/100 [==============================] - 0s 48us/step - loss: 0.0250 - acc: 0.9800 - val_loss: 0.0276 - val_acc: 0.9600\n",
      "Epoch 841/1000\n",
      "100/100 [==============================] - 0s 44us/step - loss: 0.0250 - acc: 0.9800 - val_loss: 0.0278 - val_acc: 0.9600\n",
      "Epoch 842/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0312 - acc: 0.971 - 0s 46us/step - loss: 0.0250 - acc: 0.9800 - val_loss: 0.0279 - val_acc: 0.9600\n",
      "Epoch 843/1000\n",
      "100/100 [==============================] - 0s 63us/step - loss: 0.0250 - acc: 0.9800 - val_loss: 0.0282 - val_acc: 0.9600\n",
      "Epoch 844/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.0252 - acc: 0.9800 - val_loss: 0.0286 - val_acc: 0.9600\n",
      "Epoch 845/1000\n",
      "100/100 [==============================] - 0s 40us/step - loss: 0.0249 - acc: 0.9800 - val_loss: 0.0282 - val_acc: 0.9600\n",
      "Epoch 846/1000\n",
      "100/100 [==============================] - 0s 45us/step - loss: 0.0250 - acc: 0.9800 - val_loss: 0.0275 - val_acc: 0.9600\n",
      "Epoch 847/1000\n",
      "100/100 [==============================] - 0s 43us/step - loss: 0.0248 - acc: 0.9800 - val_loss: 0.0262 - val_acc: 0.9800\n",
      "Epoch 848/1000\n",
      "100/100 [==============================] - 0s 42us/step - loss: 0.0251 - acc: 0.9800 - val_loss: 0.0254 - val_acc: 0.9800\n",
      "Epoch 849/1000\n",
      "100/100 [==============================] - 0s 40us/step - loss: 0.0251 - acc: 0.9800 - val_loss: 0.0251 - val_acc: 0.9800\n",
      "Epoch 850/1000\n",
      "100/100 [==============================] - 0s 49us/step - loss: 0.0252 - acc: 0.9800 - val_loss: 0.0249 - val_acc: 0.9800\n",
      "Epoch 851/1000\n",
      "100/100 [==============================] - 0s 42us/step - loss: 0.0252 - acc: 0.9800 - val_loss: 0.0248 - val_acc: 0.9800\n",
      "Epoch 852/1000\n",
      "100/100 [==============================] - 0s 44us/step - loss: 0.0252 - acc: 0.9800 - val_loss: 0.0247 - val_acc: 0.9800\n",
      "Epoch 853/1000\n",
      "100/100 [==============================] - 0s 42us/step - loss: 0.0252 - acc: 0.9800 - val_loss: 0.0247 - val_acc: 0.9800\n",
      "Epoch 854/1000\n",
      "100/100 [==============================] - 0s 40us/step - loss: 0.0251 - acc: 0.9800 - val_loss: 0.0249 - val_acc: 0.9800\n",
      "Epoch 855/1000\n",
      "100/100 [==============================] - 0s 40us/step - loss: 0.0249 - acc: 0.9800 - val_loss: 0.0254 - val_acc: 0.9800\n",
      "Epoch 856/1000\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.0248 - acc: 0.9800 - val_loss: 0.0263 - val_acc: 0.9600\n",
      "Epoch 857/1000\n",
      "100/100 [==============================] - 0s 41us/step - loss: 0.0246 - acc: 0.9800 - val_loss: 0.0272 - val_acc: 0.9600\n",
      "Epoch 858/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.0250 - acc: 0.9800 - val_loss: 0.0280 - val_acc: 0.9800\n",
      "Epoch 859/1000\n",
      "100/100 [==============================] - 0s 42us/step - loss: 0.0246 - acc: 0.9800 - val_loss: 0.0278 - val_acc: 0.9800\n",
      "Epoch 860/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.0247 - acc: 0.9800 - val_loss: 0.0277 - val_acc: 0.9800\n",
      "Epoch 861/1000\n",
      "100/100 [==============================] - 0s 131us/step - loss: 0.0246 - acc: 0.9800 - val_loss: 0.0278 - val_acc: 0.9800\n",
      "Epoch 862/1000\n",
      "100/100 [==============================] - 0s 108us/step - loss: 0.0246 - acc: 0.9800 - val_loss: 0.0276 - val_acc: 0.9800\n",
      "Epoch 863/1000\n",
      "100/100 [==============================] - 0s 79us/step - loss: 0.0245 - acc: 0.9800 - val_loss: 0.0274 - val_acc: 0.9800\n",
      "Epoch 864/1000\n",
      "100/100 [==============================] - 0s 89us/step - loss: 0.0245 - acc: 0.9800 - val_loss: 0.0269 - val_acc: 0.9600\n",
      "Epoch 865/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0244 - acc: 0.9800 - val_loss: 0.0261 - val_acc: 0.9600\n",
      "Epoch 866/1000\n",
      "100/100 [==============================] - 0s 82us/step - loss: 0.0245 - acc: 0.9800 - val_loss: 0.0254 - val_acc: 0.9600\n",
      "Epoch 867/1000\n",
      "100/100 [==============================] - 0s 84us/step - loss: 0.0246 - acc: 0.9800 - val_loss: 0.0251 - val_acc: 0.9800\n",
      "Epoch 868/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.0245 - acc: 0.9800 - val_loss: 0.0254 - val_acc: 0.9600\n",
      "Epoch 869/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 0.0247 - acc: 0.9800 - val_loss: 0.0256 - val_acc: 0.9600\n",
      "Epoch 870/1000\n",
      "100/100 [==============================] - 0s 86us/step - loss: 0.0244 - acc: 0.9800 - val_loss: 0.0253 - val_acc: 0.9600\n",
      "Epoch 871/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0246 - acc: 0.9800 - val_loss: 0.0251 - val_acc: 0.9800\n",
      "Epoch 872/1000\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.0244 - acc: 0.9800 - val_loss: 0.0255 - val_acc: 0.9600\n",
      "Epoch 873/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.0245 - acc: 0.9800 - val_loss: 0.0258 - val_acc: 0.9600\n",
      "Epoch 874/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.0243 - acc: 0.9800 - val_loss: 0.0257 - val_acc: 0.9600\n",
      "Epoch 875/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0204 - acc: 0.985 - 0s 58us/step - loss: 0.0245 - acc: 0.9800 - val_loss: 0.0256 - val_acc: 0.9600\n",
      "Epoch 876/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0242 - acc: 0.9800 - val_loss: 0.0263 - val_acc: 0.9600\n",
      "Epoch 877/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0245 - acc: 0.9800 - val_loss: 0.0268 - val_acc: 0.9800\n",
      "Epoch 878/1000\n",
      "100/100 [==============================] - 0s 108us/step - loss: 0.0241 - acc: 0.9800 - val_loss: 0.0266 - val_acc: 0.9600\n",
      "Epoch 879/1000\n",
      "100/100 [==============================] - 0s 76us/step - loss: 0.0241 - acc: 0.9800 - val_loss: 0.0263 - val_acc: 0.9600\n",
      "Epoch 880/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0241 - acc: 0.9800 - val_loss: 0.0262 - val_acc: 0.9600\n",
      "Epoch 881/1000\n",
      "100/100 [==============================] - 0s 81us/step - loss: 0.0241 - acc: 0.9800 - val_loss: 0.0260 - val_acc: 0.9600\n",
      "Epoch 882/1000\n",
      "100/100 [==============================] - 0s 45us/step - loss: 0.0241 - acc: 0.9800 - val_loss: 0.0260 - val_acc: 0.9600\n",
      "Epoch 883/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.0241 - acc: 0.9800 - val_loss: 0.0260 - val_acc: 0.9600\n",
      "Epoch 884/1000\n",
      "100/100 [==============================] - 0s 85us/step - loss: 0.0242 - acc: 0.9800 - val_loss: 0.0261 - val_acc: 0.9600\n",
      "Epoch 885/1000\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.0240 - acc: 0.9800 - val_loss: 0.0259 - val_acc: 0.9600\n",
      "Epoch 886/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0240 - acc: 0.9800 - val_loss: 0.0259 - val_acc: 0.9600\n",
      "Epoch 887/1000\n",
      "100/100 [==============================] - 0s 46us/step - loss: 0.0240 - acc: 0.9800 - val_loss: 0.0261 - val_acc: 0.9600\n",
      "Epoch 888/1000\n",
      "100/100 [==============================] - 0s 75us/step - loss: 0.0239 - acc: 0.9800 - val_loss: 0.0263 - val_acc: 0.9600\n",
      "Epoch 889/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.0239 - acc: 0.9800 - val_loss: 0.0265 - val_acc: 0.9600\n",
      "Epoch 890/1000\n",
      "100/100 [==============================] - 0s 79us/step - loss: 0.0239 - acc: 0.9800 - val_loss: 0.0265 - val_acc: 0.9600\n",
      "Epoch 891/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0304 - acc: 0.971 - 0s 63us/step - loss: 0.0239 - acc: 0.9800 - val_loss: 0.0264 - val_acc: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 892/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 0.0239 - acc: 0.9800 - val_loss: 0.0265 - val_acc: 0.9600\n",
      "Epoch 893/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.0238 - acc: 0.9800 - val_loss: 0.0267 - val_acc: 0.9600\n",
      "Epoch 894/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0239 - acc: 0.9800 - val_loss: 0.0269 - val_acc: 0.9600\n",
      "Epoch 895/1000\n",
      "100/100 [==============================] - 0s 72us/step - loss: 0.0238 - acc: 0.9800 - val_loss: 0.0266 - val_acc: 0.9600\n",
      "Epoch 896/1000\n",
      "100/100 [==============================] - 0s 69us/step - loss: 0.0238 - acc: 0.9800 - val_loss: 0.0264 - val_acc: 0.9600\n",
      "Epoch 897/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.0238 - acc: 0.9800 - val_loss: 0.0265 - val_acc: 0.9600\n",
      "Epoch 898/1000\n",
      "100/100 [==============================] - 0s 47us/step - loss: 0.0238 - acc: 0.9800 - val_loss: 0.0264 - val_acc: 0.9600\n",
      "Epoch 899/1000\n",
      "100/100 [==============================] - 0s 102us/step - loss: 0.0237 - acc: 0.9800 - val_loss: 0.0260 - val_acc: 0.9600\n",
      "Epoch 900/1000\n",
      "100/100 [==============================] - 0s 45us/step - loss: 0.0237 - acc: 0.9800 - val_loss: 0.0254 - val_acc: 0.9600\n",
      "Epoch 901/1000\n",
      "100/100 [==============================] - 0s 81us/step - loss: 0.0238 - acc: 0.9800 - val_loss: 0.0249 - val_acc: 0.9800\n",
      "Epoch 902/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.0238 - acc: 0.9800 - val_loss: 0.0248 - val_acc: 0.9800\n",
      "Epoch 903/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.0238 - acc: 0.9800 - val_loss: 0.0247 - val_acc: 0.9800\n",
      "Epoch 904/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0238 - acc: 0.9800 - val_loss: 0.0247 - val_acc: 0.9600\n",
      "Epoch 905/1000\n",
      "100/100 [==============================] - 0s 47us/step - loss: 0.0238 - acc: 0.9800 - val_loss: 0.0250 - val_acc: 0.9600\n",
      "Epoch 906/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0236 - acc: 0.9800 - val_loss: 0.0250 - val_acc: 0.9600\n",
      "Epoch 907/1000\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.0236 - acc: 0.9800 - val_loss: 0.0253 - val_acc: 0.9600\n",
      "Epoch 908/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.0235 - acc: 0.9800 - val_loss: 0.0256 - val_acc: 0.9600\n",
      "Epoch 909/1000\n",
      "100/100 [==============================] - 0s 96us/step - loss: 0.0237 - acc: 0.9800 - val_loss: 0.0262 - val_acc: 0.9600\n",
      "Epoch 910/1000\n",
      "100/100 [==============================] - 0s 66us/step - loss: 0.0235 - acc: 0.9800 - val_loss: 0.0261 - val_acc: 0.9600\n",
      "Epoch 911/1000\n",
      "100/100 [==============================] - 0s 87us/step - loss: 0.0235 - acc: 0.9800 - val_loss: 0.0261 - val_acc: 0.9600\n",
      "Epoch 912/1000\n",
      "100/100 [==============================] - 0s 49us/step - loss: 0.0235 - acc: 0.9800 - val_loss: 0.0262 - val_acc: 0.9600\n",
      "Epoch 913/1000\n",
      "100/100 [==============================] - 0s 116us/step - loss: 0.0235 - acc: 0.9800 - val_loss: 0.0267 - val_acc: 0.9800\n",
      "Epoch 914/1000\n",
      "100/100 [==============================] - 0s 45us/step - loss: 0.0235 - acc: 0.9800 - val_loss: 0.0269 - val_acc: 0.9800\n",
      "Epoch 915/1000\n",
      "100/100 [==============================] - 0s 79us/step - loss: 0.0234 - acc: 0.9800 - val_loss: 0.0274 - val_acc: 0.9800\n",
      "Epoch 916/1000\n",
      "100/100 [==============================] - 0s 46us/step - loss: 0.0235 - acc: 0.9800 - val_loss: 0.0277 - val_acc: 0.9800\n",
      "Epoch 917/1000\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.0235 - acc: 0.9800 - val_loss: 0.0276 - val_acc: 0.9800\n",
      "Epoch 918/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.0235 - acc: 0.9800 - val_loss: 0.0274 - val_acc: 0.9800\n",
      "Epoch 919/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.0234 - acc: 0.9800 - val_loss: 0.0274 - val_acc: 0.9800\n",
      "Epoch 920/1000\n",
      "100/100 [==============================] - 0s 48us/step - loss: 0.0234 - acc: 0.9800 - val_loss: 0.0274 - val_acc: 0.9800\n",
      "Epoch 921/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0234 - acc: 0.9800 - val_loss: 0.0275 - val_acc: 0.9800\n",
      "Epoch 922/1000\n",
      "100/100 [==============================] - 0s 49us/step - loss: 0.0234 - acc: 0.9800 - val_loss: 0.0274 - val_acc: 0.9800\n",
      "Epoch 923/1000\n",
      "100/100 [==============================] - 0s 87us/step - loss: 0.0234 - acc: 0.9800 - val_loss: 0.0271 - val_acc: 0.9800\n",
      "Epoch 924/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0085 - acc: 1.000 - 0s 57us/step - loss: 0.0233 - acc: 0.9800 - val_loss: 0.0267 - val_acc: 0.9800\n",
      "Epoch 925/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.0234 - acc: 0.9800 - val_loss: 0.0260 - val_acc: 0.9800\n",
      "Epoch 926/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.0232 - acc: 0.9800 - val_loss: 0.0256 - val_acc: 0.9800\n",
      "Epoch 927/1000\n",
      "100/100 [==============================] - 0s 44us/step - loss: 0.0232 - acc: 0.9800 - val_loss: 0.0253 - val_acc: 0.9600\n",
      "Epoch 928/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0231 - acc: 0.9800 - val_loss: 0.0253 - val_acc: 0.9600\n",
      "Epoch 929/1000\n",
      "100/100 [==============================] - 0s 83us/step - loss: 0.0231 - acc: 0.9800 - val_loss: 0.0255 - val_acc: 0.9800\n",
      "Epoch 930/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.0231 - acc: 0.9800 - val_loss: 0.0261 - val_acc: 0.9800\n",
      "Epoch 931/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.0231 - acc: 0.9800 - val_loss: 0.0268 - val_acc: 0.9800\n",
      "Epoch 932/1000\n",
      "100/100 [==============================] - 0s 77us/step - loss: 0.0232 - acc: 0.9800 - val_loss: 0.0270 - val_acc: 0.9800\n",
      "Epoch 933/1000\n",
      "100/100 [==============================] - 0s 68us/step - loss: 0.0232 - acc: 0.9800 - val_loss: 0.0266 - val_acc: 0.9800\n",
      "Epoch 934/1000\n",
      "100/100 [==============================] - 0s 68us/step - loss: 0.0231 - acc: 0.9800 - val_loss: 0.0263 - val_acc: 0.9800\n",
      "Epoch 935/1000\n",
      "100/100 [==============================] - 0s 73us/step - loss: 0.0232 - acc: 0.9800 - val_loss: 0.0259 - val_acc: 0.9800\n",
      "Epoch 936/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0230 - acc: 0.9800 - val_loss: 0.0259 - val_acc: 0.9800\n",
      "Epoch 937/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0230 - acc: 0.9800 - val_loss: 0.0258 - val_acc: 0.9800\n",
      "Epoch 938/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0230 - acc: 0.9800 - val_loss: 0.0254 - val_acc: 0.9800\n",
      "Epoch 939/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.0229 - acc: 0.9800 - val_loss: 0.0248 - val_acc: 0.9800\n",
      "Epoch 940/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.0229 - acc: 0.9800 - val_loss: 0.0243 - val_acc: 0.9600\n",
      "Epoch 941/1000\n",
      "100/100 [==============================] - 0s 81us/step - loss: 0.0229 - acc: 0.9800 - val_loss: 0.0238 - val_acc: 0.9600\n",
      "Epoch 942/1000\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.0229 - acc: 0.9800 - val_loss: 0.0236 - val_acc: 0.9600\n",
      "Epoch 943/1000\n",
      "100/100 [==============================] - 0s 47us/step - loss: 0.0230 - acc: 0.9800 - val_loss: 0.0235 - val_acc: 0.9600\n",
      "Epoch 944/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.0230 - acc: 0.9800 - val_loss: 0.0233 - val_acc: 0.9600\n",
      "Epoch 945/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0232 - acc: 0.9800 - val_loss: 0.0234 - val_acc: 0.9600\n",
      "Epoch 946/1000\n",
      "100/100 [==============================] - 0s 88us/step - loss: 0.0229 - acc: 0.9800 - val_loss: 0.0244 - val_acc: 0.9800\n",
      "Epoch 947/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.0227 - acc: 0.9800 - val_loss: 0.0254 - val_acc: 0.9800\n",
      "Epoch 948/1000\n",
      "100/100 [==============================] - 0s 73us/step - loss: 0.0228 - acc: 0.9800 - val_loss: 0.0265 - val_acc: 0.9800\n",
      "Epoch 949/1000\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.0229 - acc: 0.9800 - val_loss: 0.0273 - val_acc: 0.9800\n",
      "Epoch 950/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0232 - acc: 0.9800 - val_loss: 0.0282 - val_acc: 0.9800\n",
      "Epoch 951/1000\n",
      "100/100 [==============================] - 0s 75us/step - loss: 0.0232 - acc: 0.9900 - val_loss: 0.0282 - val_acc: 0.9800\n",
      "Epoch 952/1000\n",
      "100/100 [==============================] - 0s 77us/step - loss: 0.0233 - acc: 0.9900 - val_loss: 0.0277 - val_acc: 0.9800\n",
      "Epoch 953/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.0229 - acc: 0.9800 - val_loss: 0.0261 - val_acc: 0.9800\n",
      "Epoch 954/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.0225 - acc: 0.9800 - val_loss: 0.0245 - val_acc: 0.9600\n",
      "Epoch 955/1000\n",
      "100/100 [==============================] - 0s 74us/step - loss: 0.0227 - acc: 0.9800 - val_loss: 0.0232 - val_acc: 0.9800\n",
      "Epoch 956/1000\n",
      "100/100 [==============================] - 0s 66us/step - loss: 0.0228 - acc: 0.9800 - val_loss: 0.0225 - val_acc: 0.9800\n",
      "Epoch 957/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0233 - acc: 0.9800 - val_loss: 0.0221 - val_acc: 0.9800\n",
      "Epoch 958/1000\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.0233 - acc: 0.9800 - val_loss: 0.0223 - val_acc: 0.9800\n",
      "Epoch 959/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0233 - acc: 0.9800 - val_loss: 0.0227 - val_acc: 0.9800\n",
      "Epoch 960/1000\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.0229 - acc: 0.9800 - val_loss: 0.0230 - val_acc: 0.9800\n",
      "Epoch 961/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0229 - acc: 0.9800 - val_loss: 0.0238 - val_acc: 0.9600\n",
      "Epoch 962/1000\n",
      "100/100 [==============================] - 0s 113us/step - loss: 0.0227 - acc: 0.9800 - val_loss: 0.0243 - val_acc: 0.9600\n",
      "Epoch 963/1000\n",
      "100/100 [==============================] - 0s 66us/step - loss: 0.0225 - acc: 0.9800 - val_loss: 0.0246 - val_acc: 0.9800\n",
      "Epoch 964/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.0224 - acc: 0.9800 - val_loss: 0.0250 - val_acc: 0.9800\n",
      "Epoch 965/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 0.0225 - acc: 0.9800 - val_loss: 0.0255 - val_acc: 0.9800\n",
      "Epoch 966/1000\n",
      "100/100 [==============================] - 0s 75us/step - loss: 0.0225 - acc: 0.9800 - val_loss: 0.0258 - val_acc: 0.9800\n",
      "Epoch 967/1000\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.0227 - acc: 0.9800 - val_loss: 0.0263 - val_acc: 0.9800\n",
      "Epoch 968/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.0227 - acc: 0.9900 - val_loss: 0.0262 - val_acc: 0.9800\n",
      "Epoch 969/1000\n",
      "100/100 [==============================] - 0s 81us/step - loss: 0.0228 - acc: 0.9900 - val_loss: 0.0255 - val_acc: 0.9800\n",
      "Epoch 970/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0225 - acc: 0.9800 - val_loss: 0.0241 - val_acc: 0.9800\n",
      "Epoch 971/1000\n",
      "100/100 [==============================] - 0s 138us/step - loss: 0.0226 - acc: 0.9800 - val_loss: 0.0231 - val_acc: 0.9800\n",
      "Epoch 972/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 0.0224 - acc: 0.9800 - val_loss: 0.0227 - val_acc: 0.9600\n",
      "Epoch 973/1000\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.0225 - acc: 0.9800 - val_loss: 0.0225 - val_acc: 0.9600\n",
      "Epoch 974/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0225 - acc: 0.9800 - val_loss: 0.0227 - val_acc: 0.9600\n",
      "Epoch 975/1000\n",
      "100/100 [==============================] - 0s 47us/step - loss: 0.0224 - acc: 0.9800 - val_loss: 0.0233 - val_acc: 0.9800\n",
      "Epoch 976/1000\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.0226 - acc: 0.9800 - val_loss: 0.0238 - val_acc: 0.9800\n",
      "Epoch 977/1000\n",
      "100/100 [==============================] - 0s 94us/step - loss: 0.0223 - acc: 0.9800 - val_loss: 0.0239 - val_acc: 0.9800\n",
      "Epoch 978/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.0223 - acc: 0.9800 - val_loss: 0.0241 - val_acc: 0.9800\n",
      "Epoch 979/1000\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.0223 - acc: 0.9800 - val_loss: 0.0245 - val_acc: 0.9800\n",
      "Epoch 980/1000\n",
      "100/100 [==============================] - 0s 86us/step - loss: 0.0225 - acc: 0.9800 - val_loss: 0.0243 - val_acc: 0.9800\n",
      "Epoch 981/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.0222 - acc: 0.9800 - val_loss: 0.0234 - val_acc: 0.9800\n",
      "Epoch 982/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.0222 - acc: 0.9800 - val_loss: 0.0228 - val_acc: 0.9600\n",
      "Epoch 983/1000\n",
      "100/100 [==============================] - 0s 84us/step - loss: 0.0225 - acc: 0.9800 - val_loss: 0.0227 - val_acc: 0.9600\n",
      "Epoch 984/1000\n",
      "100/100 [==============================] - 0s 79us/step - loss: 0.0223 - acc: 0.9800 - val_loss: 0.0231 - val_acc: 0.9600\n",
      "Epoch 985/1000\n",
      "100/100 [==============================] - 0s 76us/step - loss: 0.0222 - acc: 0.9800 - val_loss: 0.0235 - val_acc: 0.9600\n",
      "Epoch 986/1000\n",
      "100/100 [==============================] - 0s 68us/step - loss: 0.0222 - acc: 0.9800 - val_loss: 0.0239 - val_acc: 0.9600\n",
      "Epoch 987/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 0.0221 - acc: 0.9800 - val_loss: 0.0246 - val_acc: 0.9800\n",
      "Epoch 988/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.0221 - acc: 0.9800 - val_loss: 0.0252 - val_acc: 0.9800\n",
      "Epoch 989/1000\n",
      "100/100 [==============================] - 0s 46us/step - loss: 0.0221 - acc: 0.9800 - val_loss: 0.0260 - val_acc: 0.9800\n",
      "Epoch 990/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.0222 - acc: 0.9800 - val_loss: 0.0267 - val_acc: 0.9800\n",
      "Epoch 991/1000\n",
      "100/100 [==============================] - 0s 96us/step - loss: 0.0223 - acc: 0.9800 - val_loss: 0.0272 - val_acc: 0.9800\n",
      "Epoch 992/1000\n",
      "100/100 [==============================] - 0s 136us/step - loss: 0.0224 - acc: 0.9800 - val_loss: 0.0269 - val_acc: 0.9800\n",
      "Epoch 993/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0223 - acc: 0.9800 - val_loss: 0.0262 - val_acc: 0.9800\n",
      "Epoch 994/1000\n",
      "100/100 [==============================] - 0s 84us/step - loss: 0.0221 - acc: 0.9800 - val_loss: 0.0255 - val_acc: 0.9800\n",
      "Epoch 995/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0173 - acc: 0.985 - 0s 54us/step - loss: 0.0220 - acc: 0.9800 - val_loss: 0.0248 - val_acc: 0.9800\n",
      "Epoch 996/1000\n",
      "100/100 [==============================] - 0s 93us/step - loss: 0.0223 - acc: 0.9800 - val_loss: 0.0242 - val_acc: 0.9800\n",
      "Epoch 997/1000\n",
      "100/100 [==============================] - 0s 77us/step - loss: 0.0220 - acc: 0.9800 - val_loss: 0.0243 - val_acc: 0.9800\n",
      "Epoch 998/1000\n",
      "100/100 [==============================] - 0s 66us/step - loss: 0.0222 - acc: 0.9800 - val_loss: 0.0241 - val_acc: 0.9800\n",
      "Epoch 999/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.0220 - acc: 0.9800 - val_loss: 0.0233 - val_acc: 0.9600\n",
      "Epoch 1000/1000\n",
      "100/100 [==============================] - 0s 81us/step - loss: 0.0220 - acc: 0.9800 - val_loss: 0.0229 - val_acc: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2bf56faf60>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DEEP LEARNING(Classification using on one-hot-encoding)\n",
    "\n",
    "print (x_train.shape)\n",
    "print (onehot_encoded.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=4, activation='relu'))\n",
    "model.add(Dense(6, activation='tanh'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='/tmp/tflearn_logs/', histogram_freq=0, write_graph=True,\n",
    "                                         write_images=False, embeddings_freq=0, embeddings_layer_names=None,\n",
    "                                         embeddings_metadata=None)\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=1000, batch_size=70, validation_data=(x_test, y_test), callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.44426341e-04   9.96279061e-01   2.77654734e-03]\n",
      " [  9.98999178e-01   9.10588482e-04   9.02921602e-05]\n",
      " [  2.93592311e-05   4.58763825e-04   9.99511838e-01]\n",
      " [  1.80797884e-03   9.84594822e-01   1.35972202e-02]\n",
      " [  1.18185789e-03   9.89081979e-01   9.73607413e-03]\n",
      " [  9.99023795e-01   8.83470580e-04   9.27694782e-05]\n",
      " [  1.01221539e-03   9.98409450e-01   5.78328443e-04]\n",
      " [  1.78010872e-04   6.69987360e-03   9.93122160e-01]\n",
      " [  1.35432521e-03   2.77316004e-01   7.21329629e-01]\n",
      " [  7.02517107e-04   9.98642027e-01   6.55424898e-04]\n",
      " [  1.45167881e-03   1.18334621e-01   8.80213678e-01]\n",
      " [  9.98710871e-01   1.20240136e-03   8.67946510e-05]\n",
      " [  9.99142051e-01   7.65384466e-04   9.25256245e-05]\n",
      " [  9.98640716e-01   1.27347314e-03   8.57996129e-05]\n",
      " [  9.98769939e-01   1.14377413e-03   8.63079840e-05]\n",
      " [  1.50332169e-03   9.93759692e-01   4.73692361e-03]\n",
      " [  5.64426591e-05   1.22891273e-03   9.98714685e-01]\n",
      " [  6.74080104e-04   9.98522460e-01   8.03499133e-04]\n",
      " [  1.34288927e-03   9.93192494e-01   5.46466839e-03]\n",
      " [  4.97969777e-05   1.04607944e-03   9.98904109e-01]\n",
      " [  9.97956395e-01   1.96203566e-03   8.16621396e-05]\n",
      " [  2.65749893e-03   3.18679065e-01   6.78663373e-01]\n",
      " [  9.98564541e-01   1.34708593e-03   8.84412511e-05]\n",
      " [  6.08271184e-05   1.47359027e-03   9.98465657e-01]\n",
      " [  1.67483452e-03   1.74825877e-01   8.23499322e-01]\n",
      " [  9.77681411e-05   2.80546723e-03   9.97096777e-01]\n",
      " [  6.63093160e-05   2.25860672e-03   9.97675121e-01]\n",
      " [  6.12341319e-05   1.35224033e-03   9.98586535e-01]\n",
      " [  9.98731911e-01   1.17794122e-03   9.01332896e-05]\n",
      " [  9.98249054e-01   1.66652491e-03   8.44486058e-05]\n",
      " [  9.98947561e-01   9.64597508e-04   8.79148356e-05]\n",
      " [  9.99083638e-01   8.25677358e-04   9.06262503e-05]\n",
      " [  7.62254756e-04   9.98414874e-01   8.22946720e-04]\n",
      " [  9.98140574e-01   1.77799270e-03   8.13287552e-05]\n",
      " [  9.98279929e-01   1.63784798e-03   8.22314541e-05]\n",
      " [  1.33427879e-04   5.85862063e-03   9.94007945e-01]\n",
      " [  9.40982427e-04   9.97514844e-01   1.54416799e-03]\n",
      " [  9.98886764e-01   1.02500175e-03   8.82327658e-05]\n",
      " [  9.98825729e-01   1.08752667e-03   8.66904666e-05]\n",
      " [  9.98773634e-01   1.14218472e-03   8.42170484e-05]\n",
      " [  1.56767259e-04   5.75031247e-03   9.94092882e-01]\n",
      " [  1.32012111e-03   9.96455550e-01   2.22434825e-03]\n",
      " [  1.06022262e-03   9.95674074e-01   3.26576200e-03]\n",
      " [  9.99106109e-01   8.02025548e-04   9.18156802e-05]\n",
      " [  9.98991668e-01   9.19007813e-04   8.93376491e-05]\n",
      " [  6.87337422e-04   9.98773873e-01   5.38766966e-04]\n",
      " [  2.77347420e-03   6.97679043e-01   2.99547523e-01]\n",
      " [  8.84743116e-04   6.82971552e-02   9.30818081e-01]\n",
      " [  7.25672056e-04   9.98198569e-01   1.07583380e-03]\n",
      " [  6.97916330e-05   1.49168225e-03   9.98438537e-01]]\n",
      "(50, 4)\n",
      "Versicolor\n",
      "Setosa\n",
      "Verginica\n",
      "Versicolor\n",
      "Versicolor\n",
      "Setosa\n",
      "Versicolor\n",
      "Verginica\n",
      "Verginica\n",
      "Versicolor\n",
      "Verginica\n",
      "Setosa\n",
      "Setosa\n",
      "Setosa\n",
      "Setosa\n",
      "Versicolor\n",
      "Verginica\n",
      "Versicolor\n",
      "Versicolor\n",
      "Verginica\n",
      "Setosa\n",
      "Verginica\n",
      "Setosa\n",
      "Verginica\n",
      "Verginica\n",
      "Verginica\n",
      "Verginica\n",
      "Verginica\n",
      "Setosa\n",
      "Setosa\n",
      "Setosa\n",
      "Setosa\n",
      "Versicolor\n",
      "Setosa\n",
      "Setosa\n",
      "Verginica\n",
      "Versicolor\n",
      "Setosa\n",
      "Setosa\n",
      "Setosa\n",
      "Verginica\n",
      "Versicolor\n",
      "Versicolor\n",
      "Setosa\n",
      "Setosa\n",
      "Versicolor\n",
      "Versicolor\n",
      "Verginica\n",
      "Versicolor\n",
      "Verginica\n"
     ]
    }
   ],
   "source": [
    "#Working of One Hot Encoding explained using the test case\n",
    "\n",
    "lab = ['Setosa','Versicolor','Verginica']\n",
    "op = model.predict(x_test)\n",
    "print(op)\n",
    "print(x_test.shape)\n",
    "for i in range(0,50):\n",
    "     print(lab[np.argmax(op[i])])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e885825c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_test,prediction)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuySVkOEuSSX0/wGxy1US1aLR5AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e88680ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test,prediction)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "trial = knn.predict([[5.9,4.7,3.9,5.1]])\n",
    "print(trial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
